{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Multimodal-Agent","text":"<p>A lightweight, production-ready wrapper around Google Gemini offering:</p> <ul> <li>A powerful CLI (<code>agent</code>)</li> <li>Code generation for Flutter (widgets, screens, models)</li> <li>RAG memory with SQLite</li> <li>FastAPI server mode</li> <li>Image + text multimodal queries</li> <li>JSON output mode</li> <li>Project learning &amp; analysis</li> <li>Offline / fake-response mode for testing</li> <li>Clean usage logging &amp; retry/backoff</li> <li>Syntax-aware output formatting</li> </ul> <p>Latest version: v0.8.0</p>"},{"location":"#contents","title":"Contents","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation</li> <li>Quickstart</li> <li>CLI Usage</li> <li>Python API</li> </ul>"},{"location":"#core-system","title":"Core System","text":"<ul> <li>Architecture Overview</li> <li>Sessions</li> <li>RAG System</li> <li>History Management</li> <li>Configuration</li> </ul>"},{"location":"#code-generation-v080","title":"Code Generation (v0.8.0)","text":"<ul> <li>Flutter Codegen Overview</li> <li>Widget / Screen / Model Generation</li> </ul>"},{"location":"#advanced-features","title":"Advanced Features","text":"<ul> <li>Response Metadata Schema</li> <li>JSON Response Mode</li> <li>Token Usage Logging</li> <li>Usage Logging Behavior</li> <li>Server API</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Text generation</li> <li>Image + text multimodal input</li> <li>Local RAG using SQLite</li> <li>Project-aware learning &amp; analysis</li> <li>Interactive chat sessions</li> <li>Token accounting &amp; logging</li> <li>Offline fake-mode for deterministic tests</li> <li>Syntax-aware code formatting</li> <li>Flutter code generation:</li> <li><code>agent gen widget</code></li> <li><code>agent gen screen</code></li> <li><code>agent gen model</code></li> </ul>"},{"location":"#quick-install","title":"Quick Install","text":"<p><pre><code>pip install multimodal-agent\n</code></pre> Set your API key: <pre><code>export GOOGLE_API_KEY=\"your-api-key\"\n</code></pre> No key? The CLI and Python API still work in offline fake mode, returning predictable response for testing.</p>"},{"location":"#need-help","title":"need help?","text":"<p>Open an issue on Github or submit a pull request. Contribution to docs, tests, and performance improvements are always welcome.</p>"},{"location":"agent/","title":"Agent Overview","text":"<p>The Multimodal Agent is the core high-level interface for interacting with Google Gemini. It supports text, image+text questions, JSON responses, RAG-enhanced conversations, and offline fake-mode for deterministic testing.</p> <p>This document explains how the agent works and how to use it programmatically.</p>"},{"location":"agent/#importing-the-agent","title":"Importing the Agent","text":"<pre><code>from multimodal_agent.core.agent_core import MultiModalAgent\n</code></pre> <p>Create an agent instance: <pre><code>agent = MultiModalAgent(\n    model=\"gemini-2.5-flash\",\n    enable_rag=True,   # enables SQLite RAG memory\n)\n</code></pre></p> <p>If no API key is found in environment variables, offline fake-mode is activated automatically.</p>"},{"location":"agent/#basic-text-generation","title":"Basic Text Generation","text":"<pre><code>response = agent.ask(\"Explain flutter widgets.\")\nprint(response.text)\n</code></pre> <p>Returned object: AgentResponse</p> <pre><code>AgentResponse(\n    text=\"...\", \n    data=None, \n    usage={\"prompt_tokens\": ..., \"response_tokens\": ..., \"total_tokens\": ...}\n)\n</code></pre>"},{"location":"agent/#image-text-questions","title":"Image + Text Questions","text":"<p><pre><code>from multimodal_agent.utils import load_image_as_part\n\nimage = load_image_as_part(\"cat.png\")\nresponse = agent.ask_with_image(\"Describe the image\", image)\nprint(response.text)\n</code></pre> Supports: -   JPG / PNG -   Multiple images (if model supports it)</p>"},{"location":"agent/#json-mode","title":"JSON Mode","text":"<p>The agent can force the model to produce strict JSON: <pre><code>response = agent.ask(\n    \"Give me a summary with fields title and score\",\n    response_format=\"json\",\n)\nprint(response.data)\n</code></pre></p> <p>Output example: <pre><code>{\n  \"title\": \"Summary\",\n  \"score\": 9\n}\n</code></pre></p> <p>If JSON parsing fails, an AgentError is raised.</p>"},{"location":"agent/#offline-fake-mode-for-tests","title":"Offline Fake Mode (for Tests)","text":"<p>If you run the agent without an API key: <pre><code>export GOOGLE_API_KEY=\"\"\n</code></pre></p> <p>Or you omit it entirely, the agent switches to fake mode.</p> <p>Behavior:</p> Input Output agent.ask(\"hello\") Returns FAKE_RESPONSE: hello agent.ask(\"hello\",response_format=\"json\") Returns JSON encoded fake response Token usage Deterministic stub values <p>This makes CI / unit tests stable and zero-cost.</p>"},{"location":"agent/#rag-memory-system","title":"RAG Memory System","text":"<p>When enable_rag=True, the agent maintains a memory buffer in SQLite. <pre><code>agent = MultiModalAgent(enable_rag=True)\nagent.ask(\"What is object-oriented programming?\")\n</code></pre> Behind the scenes:     1.  User query \u2192 embedded     2.  Similar chunks retrieved from SQLite     3.  Prompts are augmented with retrieved context     4.  Output is saved back into memory</p> <p>To inspect memory: <pre><code>agent history show --limit 20\n</code></pre></p>"},{"location":"agent/#sessions","title":"Sessions","text":"<p>You may group interactions under a session: <pre><code>agent.ask(\"Start a new conversation\", session_id=\"research1\")\nagent.ask(\"Add more context\", session_id=\"research1\") \n</code></pre></p> <p>From CLI: <pre><code>agent ask \"Hello\" --session my_session\n</code></pre></p>"},{"location":"agent/#token-usage-tracking","title":"Token Usage Tracking","text":"<p>Every response includes a .usage field: <pre><code>print(response.usage)\n</code></pre></p> <p>Example: <pre><code>{\n  \"prompt_tokens\": 123,\n  \"response_tokens\": 45,\n  \"total_tokens\": 168\n}\n</code></pre></p> <p>Useful for monitoring cost.</p>"},{"location":"agent/#error-handling","title":"Error Handling","text":"<p>All agent-related errors raise clean subclasses of AgentError: -   Invalid JSON output -   API failures -   Timeout -   Missing image -   RAG store issues <pre><code>from multimodal_agent.errors import AgentError\n\ntry:\n    agent.ask(\"...\")\nexcept AgentError as e:\n    print(\"Agent failed:\", e)\n</code></pre></p>"},{"location":"agent/#using-custom-models","title":"Using Custom Models","text":"<pre><code>agent = MultiModalAgent(model=\"gemini-pro\")\n</code></pre> <p>From CLI: <pre><code>agent --model gemini-pro ask \"Hello\"\n</code></pre></p>"},{"location":"agent/#integration-with-code-generation-engine","title":"Integration with Code Generation Engine","text":"<p>The agent itself is independent from codegen, but the CLI uses both: <pre><code>agent gen widget HomeScreen\n</code></pre></p> <p>This internally: 1.  Builds a codegen prompt 2.  Sends it to the agent 3.  Validates output 4.  Writes the .dart file</p>"},{"location":"agent/#full-example","title":"Full Example","text":"<pre><code>from multimodal_agent.core.agent_core import MultiModalAgent\n\nagent = MultiModalAgent(enable_rag=True)\n\nresponse = agent.ask(\"Explain Riverpod in Flutter.\")\nprint(\"Answer:\", response.text)\nprint(\"Tokens:\", response.usage)\n</code></pre>"},{"location":"agent/#when-to-use-the-agent-programmatically","title":"When to Use the Agent Programmatically","text":"<p>Use the agent directly if you need: -   Embedding your app with Gemini -   Multimodal Q&amp;A -   RAG-powered assistants -   JSON-producing agents -   Offline test-safe inference</p> <p>Use CLI if you want: -   Quick questions -   Code generation -   Server hosting -   Memory debugging</p>"},{"location":"agent/#summary","title":"Summary","text":"Feature Supported Text + Image \u2714 JSON output \u2714 Offline fake mode \u2714 RAG memory \u2714 Sessions \u2714 Token usage \u2714 Project learning \u2714 Code generation engine \u2714"},{"location":"architecture/","title":"Architecture Overview","text":"<p>The Multimodal-Agent project is built as a modular, production-oriented framework around Google Gemini.</p> <p>Its architecture is designed around four core pillars:</p> <pre><code>1.  Unified Agent Core \u2014 text, image, and JSON generation\n\n2.  RAG Memory System \u2014 project-aware retrieval with SQLite\n\n3.  Code Generation Engine \u2014 Flutter/Dart widget/screen/model generator\n\n4.  Developer Tools \u2014 CLI, FastAPI server, logging, config, sessions\n</code></pre> <p>This document explains how all parts work together.</p>"},{"location":"architecture/#high-level-architecture-diagram","title":"High-Level Architecture Diagram","text":"<pre><code>                    +-------------------------+\n                    |      CLI (agent)        |\n                    +-----------+-------------+\n                                |\n                                v\n                    +-------------------------+\n                    |    MultiModalAgent      |\n                    +-----------+-------------+\n                                |\n        +-----------------------+--------------------------+\n        |                       |                          |\n        v                       v                          v\n+------------------+   +---------------------+   +-----------------------+\n|   Gemini Client  |   |      RAG Store      |   |   Codegen Engine      |\n|  (Text / Image)  |   | (SQLite Embeddings) |   | (Flutter/Dart Gen)    |\n+------------------+   +---------------------+   +-----------------------+\n        |                      |                            |\n        +-----------+----------+                            |\n                    |                                       |\n                    v                                       v\n        +-------------------------+         +---------------------------+\n        |   Prompt Builder Layer  |         |  Prompt Templates (Dart)  |\n        +-------------------------+         +---------------------------+\n</code></pre>"},{"location":"architecture/#multimodalagent-core","title":"MultiModalAgent Core","text":"<p>Located in:</p> <pre><code>multimodal_agent/core/agent_core.py\n</code></pre> <p>The agent handles:</p> <p>\u2714 Text generation</p> <p>\u2714 Image + text multimodal queries</p> <p>\u2714 JSON responses</p> <p>\u2714 Offline \u201cfake mode\u201d (no API key)</p> <p>\u2714 Token usage logging</p> <p>\u2714 RAG integration</p> <p>\u2714 Session tracking</p> <p>Internally the agent does:</p> <ol> <li> <p>Build a request</p> </li> <li> <p>Apply formatting (text or JSON)</p> </li> <li> <p>Check if RAG is enabled \u2192 perform vector search</p> </li> <li> <p>Call the Gemini API (or fake mode)</p> </li> <li> <p>Normalize output into AgentResponse</p> </li> <li> <p>Log metadata + usage</p> </li> </ol>"},{"location":"architecture/#llm-client-layer","title":"LLM Client Layer","text":"<p>Wrapper around Google Gemini 2.5 Flash and other models.</p> <p>Key features:</p> <ul> <li> <p>Auto-detect fake mode (missing API key)</p> </li> <li> <p>Retry + exponential backoff</p> </li> <li> <p>Unified ask() and ask_with_image() entrypoints</p> </li> <li> <p>Handles JSON formatting + parsing</p> </li> <li> <p>Created once per CLI invocation</p> </li> </ul> <p>This abstraction ensures your CLI and server run identically regardless of model version.</p>"},{"location":"architecture/#prompt-builder-system-new-in-v08x","title":"Prompt Builder System (New in v0.8.x)","text":"<p>All code-generation prompts are built in: <pre><code>multimodal_agent/codegen/prompts/\n</code></pre></p> <p>Files:</p> <p>\u2022   widget_prompt.py</p> <p>\u2022   screen_prompt.py</p> <p>\u2022   model_prompt.py</p> <p>Each exposes a pure function: <pre><code>def build_widget_prompt(name, stateful=False, description=\"\"):\n</code></pre></p> <p>These builders guarantee:</p> <p>\u2714 Stable structure</p> <p>\u2714 No markdown</p> <p>\u2714 No comments</p> <p>\u2714 Exact class names</p> <p>\u2714 Valid minimal Flutter code</p> <p>This solves the main problem with LLM-based generation: inconsistent prompt quality.</p>"},{"location":"architecture/#codegen-engine","title":"Codegen Engine","text":"<p>Located in: <pre><code>multimodal_agent/codegen/engine.py\n</code></pre></p> <p>Responsible for turning user input into actual files:</p> <p>Responsibilities:</p> <ul> <li> <p>Detect Flutter project root</p> </li> <li> <p>Sanitize class names (PascalCase)</p> </li> <li> <p>Convert names to snake_case paths</p> </li> <li> <p>Build LLM prompt</p> </li> <li> <p>Send request to Gemini</p> </li> <li> <p>Validate + clean Dart output</p> </li> <li> <p>Ensure imports (material.dart)</p> </li> <li> <p>Write files (widgets/, screens/, models/)</p> </li> </ul> <p>Validation includes:</p> <ul> <li> <p>Must contain exactly one class</p> </li> <li> <p>Class name must match sanitized version</p> </li> <li> <p>No comments or markdown</p> </li> <li> <p>File must be syntactically clean</p> </li> </ul> <p>If the LLM misbehaves \u2192 the engine raises a clean error.</p>"},{"location":"architecture/#rag-memory-system","title":"RAG Memory System","text":"<p>Stored in: <pre><code>multimodal_agent/rag/\n</code></pre></p> <p>Powered by SQLite embeddings, with chunk normalization and tagging.</p> <p>Supports:</p> <ul> <li> <p>Semantic search on conversation memory</p> </li> <li> <p>Project learning (v0.6+)</p> </li> <li> <p>Per-session recall</p> </li> <li> <p>Memory summaries</p> </li> <li> <p>Noise filtering</p> </li> </ul> <p>Typical workflow:</p> <pre><code>User \u2192 Query \u2192 RAG search \u2192 Append context \u2192 LLM \u2192 Store response \u2192 Update memory\n</code></pre>"},{"location":"architecture/#cli-architecture","title":"CLI Architecture","text":"<p>All commands defined in: <pre><code>multimodal_agent/cli/cli.py\n</code></pre></p> <p>Supported commands:</p> Command Purpose agent ask \"text\" Normal text queries agent image img.png \"question\" Image + text agent chat Interactive session agent gen widget FooWidget Code generation agent history Inspect RAG memory agent config set-key Configuration agent server Run FastAPI <p>Each command delegates to specialized handlers for readability + testability.</p>"},{"location":"architecture/#server-architecture","title":"Server Architecture","text":"<p>Located in: <pre><code>multimodal_agent/server/\n</code></pre></p> <p>Built with FastAPI, not Flask.</p> <p>Endpoints:</p> <ul> <li> <p>/ask</p> </li> <li> <p>/ask-image</p> </li> <li> <p>/chat</p> </li> <li> <p>/embed</p> </li> <li> <p>/health</p> </li> </ul> <p>Designed to be:</p> <p>\u2714 Production-ready</p> <p>\u2714 Stateless (sessions stored in RAG)</p> <p>\u2714 Easy to deploy (Docker + Uvicorn)</p>"},{"location":"architecture/#offline-fake-mode-critical-for-tests","title":"Offline Fake Mode (Critical for Tests)","text":"<p>If: <pre><code>GOOGLE_API_KEY=\"\"\n</code></pre></p> <p>The agent will not call Google \u2014 it instead returns: <pre><code>FAKE_RESPONSE: `&lt;prompt&gt;`\n</code></pre></p> <p>This makes:</p> <ul> <li>Unit tests fast</li> <li>Integration tests deterministic</li> <li>CI runs without API keys</li> </ul>"},{"location":"architecture/#project-learning-system","title":"Project Learning System","text":"<p>Added in v0.6.0:</p> <ul> <li>Scans a Flutter project</li> <li>Extracts structure, dependencies, files</li> <li>Generates a \u201cproject profile\u201d</li> <li>Stores it in RAG for future reasoning</li> </ul> <p>Useful for:</p> <ul> <li>Code refactoring suggestions</li> <li>Automated code reviews</li> <li>Project-aware code generation</li> </ul>"},{"location":"architecture/#utility-layer","title":"Utility Layer","text":"<p>Includes:</p> <ul> <li>File I/O</li> <li>Image loading</li> <li>Token tracking</li> <li>Path helpers</li> <li>Sanitization utilities</li> </ul>"},{"location":"architecture/#future-expansions-roadmap","title":"Future Expansions (Roadmap)","text":"<ul> <li>Codegen for:</li> <li>Repositories</li> <li>Services</li> <li>Enums</li> <li>Abstract classes</li> <li>Riverpod providers</li> <li>Feature modules</li> <li>Full Flutter project scaffolding:</li> </ul> <pre><code>agent gen app my_app\n</code></pre> <ul> <li> <p>Code analysis: <pre><code>agent analyze lib/\n</code></pre></p> </li> <li> <p>Dart formatting using dart format hook</p> </li> </ul>"},{"location":"chunk_normalization/","title":"Chunk normalization","text":"<p>Chunk Normalization (Planned Feature)</p> <p>Chunk Normalization is an upcoming enhancement to the Multimodal-Agent RAG pipeline.</p> <p>Its goal is to ensure consistent, high-quality text chunks before they are embedded and stored in the RAG database.</p> <p>Although not fully implemented in v0.8.0, parts of the system are already prepared for it, and internal components (like SQLiteRAGStore and project_scanner) are designed to support normalized content in the future.</p>"},{"location":"chunk_normalization/#purpose","title":"Purpose","text":"<p>Different data sources introduce inconsistent formatting:</p> <ul> <li>Logs may include timestamps or prefixes</li> <li>Code blocks may include prompts or comments</li> <li>LLM responses might contain markdown</li> <li>Chat transcripts may contain metadata wrappers</li> <li>Project learning may scan README files, code files, JSON metadata, etc.</li> </ul> <p>Normalization removes noise so that embeddings represent clean semantic units, enabling more accurate retrieval.</p>"},{"location":"chunk_normalization/#planned-normalization-steps","title":"Planned Normalization Steps","text":"<p>Normalization will eventually include:</p>"},{"location":"chunk_normalization/#remove-infrastructure-noise","title":"Remove infrastructure noise","text":"<ul> <li>Model test messages (FAKE_RESPONSE, timestamps)</li> <li>System metadata wrappers</li> <li>Markdown fences around code blocks</li> </ul>"},{"location":"chunk_normalization/#collapse-whitespace","title":"Collapse whitespace","text":"<ul> <li>Merge repeated blank lines</li> <li>Ensure consistent line endings</li> </ul>"},{"location":"chunk_normalization/#code-aware-cleanup","title":"Code-aware cleanup","text":"<p>When chunks contain code:</p> <ul> <li>Remove debug prints</li> <li>Strip comments</li> <li>Normalize imports</li> </ul> <p>This is not yet active but will be introduced via an optional --normalize flag.</p>"},{"location":"chunk_normalization/#deduplicate-similar-chunks","title":"Deduplicate similar chunks","text":"<p>Avoid repeatedly storing identical log entries or README excerpts.</p>"},{"location":"chunk_normalization/#semantic-sentence-splitting","title":"Semantic sentence splitting","text":"<p>Break large bodies of text into retrieval-friendly segments (~200\u2013400 tokens).</p>"},{"location":"chunk_normalization/#current-behavior-in-v080","title":"Current Behavior in v0.8.0","text":"<p>While full normalization is not done yet:</p> <ul> <li>Project scanning already creates structured profiles that are \u201cclean\u201d by design.</li> <li>Memory logs prevent noisy sources (FAKE_RESPONSE, project profiles) from cluttering history views if the --clean flag is used.</li> <li>Embedding storage is prepared to store normalized chunks once the feature is activated.</li> </ul> <p>Chunk normalization is a roadmap feature for v0.9.x or v1.0.</p>"},{"location":"chunk_normalization/#future-cli-support-planned","title":"Future CLI Support (planned)","text":"<p>Once implemented, normalization may be toggled via:</p> <pre><code>agent learn-project path/to/project --normalize\n</code></pre> <p>or</p> <pre><code>agent config set-normalization aggressive\n</code></pre> <p>Modes under consideration:</p> Mode Description none Store raw text (current behavior) light Remove noise + clean whitespace medium Code-aware cleanup + dedupe aggressive Sentence-level segmentation and transformation"},{"location":"chunk_normalization/#roadmap-placement","title":"Roadmap Placement","text":"<p>Chunk normalization is tracked for:</p> <ul> <li>v0.9.x \u2013 Introduce basic normalization pipeline</li> <li>v1.0 \u2013 Full integration with RAG + project learning</li> <li>Post-1.0 \u2013 Custom normalization profiles per project or per file type</li> </ul>"},{"location":"chunk_normalization/#summary","title":"Summary","text":"<p>Although not enabled yet, the system is already architected to support chunk normalization as a first-class feature in future versions.</p> <p>Chunk normalization will eventually:</p> <ul> <li>Improve retrieval accuracy</li> <li>Reduce database noise</li> <li>Produce cleaner embeddings</li> <li>Enhance project learning results</li> </ul>"},{"location":"cli/","title":"CLI Usage (<code>agent</code>)","text":"<p>The <code>agent</code> CLI is the main interface for interacting with the Multimodal-Agent system. It supports:</p> <ul> <li>Text queries</li> <li>Image + text queries</li> <li>Interactive chat</li> <li>RAG memory browsing</li> <li>Project learning</li> <li>Flutter code generation (v0.8.0+)</li> <li>Config management</li> <li>Running a FastAPI server</li> </ul>"},{"location":"cli/#basic-commands","title":"Basic Commands","text":""},{"location":"cli/#show-version","title":"Show version","text":"<pre><code>agent --version\n</code></pre> <p>Ask a text question</p> <pre><code>agent ask \"What is Flutter?\"\n</code></pre> <p>JSON mode</p> <pre><code>agent ask \"example\" --json\n</code></pre> <p>Disable RAG for a single query</p> <pre><code>agent ask \"hello\" --no-rag\n</code></pre>"},{"location":"cli/#image-text-queries","title":"Image + Text Queries","text":"<pre><code>agent image cat.jpg \"what is in this image?\"\n</code></pre> <p>Supports --json and --no-rag just like ask.</p>"},{"location":"cli/#interactive-chat-mode","title":"Interactive Chat Mode","text":"<pre><code>agent chat\n</code></pre> <p>With persistent session ID:</p> <pre><code>agent chat --session my-dev-session\n</code></pre> <p>Disable RAG during chat:</p> <pre><code>agent chat --no-rag\n</code></pre>"},{"location":"cli/#flutter-code-generation-v080","title":"Flutter Code Generation (v0.8.0+)","text":"<p>The CLI can generate Flutter boilerplate files:     \u2022   Widgets \u2192 lib/widgets/     \u2022   Screens \u2192 lib/screens/     \u2022   Models \u2192 lib/models/</p> <p>Run inside a Flutter project (must contain pubspec.yaml).</p> <p>\u2e3b</p> <p>Generate a stateless widget</p> <pre><code>agent gen widget MyWidget\n</code></pre> <p>Generate a stateful widget</p> <pre><code>agent gen widget Counter --stateful\n</code></pre> <p>Generate a screen</p> <pre><code>agent gen screen HomeScreen\n</code></pre> <p>Generate a model</p> <pre><code>agent gen model UserProfile\n</code></pre> <p>Overwrite existing file</p> <pre><code>agent gen widget MyWidget --override\n</code></pre> <p>All names are auto-normalized:</p> <ul> <li>Class: PascalCase</li> <li>File: snake_case.dart</li> </ul> <p>Example:</p> <pre><code>agent gen widget UserCard\n</code></pre> <p>Creates:</p> <pre><code>lib/widgets/user_card.dart\n</code></pre>"},{"location":"cli/#history-memory-rag","title":"History &amp; Memory (RAG)","text":"<p>Show recent memory</p> <pre><code>agent history show\n</code></pre> <p>Limit number of rows:</p> <pre><code>agent history show --limit 20\n</code></pre> <p>Hide noise</p> <pre><code>agent history show --clean\n</code></pre> <p>Delete all memory</p> <pre><code>agent history clear\n</code></pre> <p>Summarize memory via LLM</p> <pre><code>agent history summary\n</code></pre> <p>Delete specific memory item</p> <pre><code>agent history delete 42\n</code></pre>"},{"location":"cli/#project-learning-rag-profiles","title":"Project Learning (RAG Profiles)","text":"<p>Teach the agent about a project:</p> <pre><code>agent learn-project /path/to/project\n</code></pre> <p>Store with specific ID:</p> <pre><code>agent learn-project /app --project-id myapp\n</code></pre> <p>List learned projects:</p> <pre><code>agent list-projects\n</code></pre> <p>Show project profile:</p> <pre><code>agent show-project myapp\n</code></pre> <p>Inspect without saving:</p> <pre><code>agent inspect-project /app\n</code></pre>"},{"location":"cli/#server-mode-fastapi","title":"Server Mode (FastAPI)","text":"<p>Run a local API server:</p> <pre><code>agent server --port 8000\n</code></pre>"},{"location":"cli/#config-management","title":"Config Management","text":"<p>Set API key</p> <pre><code>agent config set-key YOUR_KEY\n</code></pre> <p>Set chat model</p> <pre><code>agent config set-model gemini-2.5-flash\n</code></pre> <p>Set image model</p> <pre><code>agent config set-image-model gemini-2.5-flash\n</code></pre> <p>Set embedding model</p> <pre><code>agent config set-embed-model text-embedding-004\n</code></pre> <p>Show full config</p> <pre><code>agent config show\n</code></pre>"},{"location":"cli/#offline-fake-mode","title":"Offline Fake Mode","text":"<p>If GOOGLE_API_KEY is missing, the agent runs in fake offline mode.</p> <p>Example:</p> <pre><code>agent ask \"hello\"\n</code></pre> <p>Output:</p> <pre><code>FAKE_RESPONSE: hello\n</code></pre> <p>Useful for:</p> <ul> <li>CI environments</li> <li>Tests</li> <li>No network access</li> </ul>"},{"location":"cli/#quota-rate-limits-free-tier","title":"Quota &amp; Rate Limits (Free Tier)","text":"<p>When using the Gemini API free tier, you may encounter:</p> <ul> <li><code>429 RESOURCE_EXHAUSTED</code></li> <li>Quota exceeded</li> <li>Temporary request failures</li> </ul> <p>This is expected behavior and not a CLI bug.</p> <p>Notes: - The CLI talks directly to Gemini and may continue working even when the server or VS Code extension fails. - Requests may succeed intermittently until quota fully resets.</p> <p>What to do: - Wait for quota reset (usually within 24 hours) - Reduce request frequency - Switch to a lighter model - Upgrade your Gemini API plan</p>"},{"location":"cli/#model-availability","title":"Model Availability","text":"<p>If you configure an unsupported or deprecated model, the CLI may fail with:</p> <ul> <li><code>404 NOT_FOUND (model)</code></li> </ul> <p>Fix: - Update your model via: <pre><code>agent config set-model gemini-2.5-flash\n</code></pre></p> <ul> <li>Verify supported models at: https://ai.google.dev/gemini-api/docs/models</li> </ul>"},{"location":"cli/#debug-logging","title":"Debug Logging","text":"<p>Enable verbose logs:</p> <pre><code>agent --debug ask \"hi\"\n</code></pre> <p>Summary of Commands</p> Category Command Text agent ask \"...\" Image agent image file.png \"...\" Chat agent chat History agent history show, clear, summary, delete Learning agent learn-project path Codegen agent gen widget/screen/model Name Server agent server Config agent config ..."},{"location":"config/","title":"Configuration","text":"<p>The Multimodal-Agent supports persistent configuration via a lightweight YAML config file.</p> <p>It allows you to store default:</p> <ul> <li>API key</li> <li>Chat model</li> <li>Image model</li> <li>Embedding model</li> </ul> <p>This removes the need to pass --model or set the environment variable every time.</p>"},{"location":"config/#where-the-config-file-lives","title":"Where the Config File Lives","text":"<p>The configuration is stored inside:</p> <pre><code>~/.multimodal_agent/config.yaml\n</code></pre> <p>Example file:</p> <pre><code>api_key: \"YOUR-KEY\"\nchat_model: \"gemini-2.5-flash\"\nimage_model: \"gemini-2.0-flash\"\nembedding_model: \"text-embedding-004\"\n</code></pre> <p>Precedence Rule</p> <p>Environment variables override config file , and ** CLI flags override both .**</p>"},{"location":"config/#managing-configuration-via-cli","title":"Managing Configuration via CLI","text":"<p>The CLI provides the agent config command for updating and inspecting your config.</p>"},{"location":"config/#set-api-key","title":"Set API Key","text":"<pre><code>agent config set-key YOUR_GOOGLE_API_KEY\n</code></pre> <p>This writes:</p> <pre><code>api_key: \"YOUR_GOOGLE_API_KEY\"\n</code></pre>"},{"location":"config/#set-default-chat-model","title":"Set Default Chat Model","text":"<pre><code>agent config set-model gemini-2.5-flash\n</code></pre> <p>This updates the chat_model field.</p>"},{"location":"config/#set-image-model","title":"Set Image Model","text":"<pre><code>agent config set-image-model gemini-2.0-flash\n</code></pre>"},{"location":"config/#set-embedding-model","title":"Set Embedding Model","text":"<pre><code>agent config set-embed-model text-embedding-004\n</code></pre>"},{"location":"config/#show-current-config","title":"Show Current Config","text":"<pre><code>agent config show\n</code></pre> <p>Example output:</p> <pre><code>api_key: \"YOUR-KEY\"\nchat_model: \"gemini-2.5-flash\"\nimage_model: \"gemini-2.5-flash\"\nembedding_model: \"text-embedding-004\"\n</code></pre>"},{"location":"config/#environment-variables","title":"Environment Variables","text":"<p>The agent also reads config from environment variables:</p> Variable Meaning GOOGLE_API_KEY API key for Gemini MULTIMODAL_AGENT_DB Override SQLite memory DB path <p>Example:</p> <pre><code>export GOOGLE_API_KEY=\"my-key\"\n</code></pre> <p>This will override anything in the config file.</p>"},{"location":"config/#how-the-agent-loads-config","title":"How the Agent Loads Config","text":"<ol> <li>Load YAML config from ~/.multimodal_agent/config.yaml</li> <li>Override with environment variables</li> <li>Override with CLI arguments (e.g., --model gemini-2.5-flash)</li> </ol> <p>So the final priority is:</p> <pre><code>CLI flags &gt; Env vars &gt; Config file defaults\n</code></pre>"},{"location":"config/#important-notes-for-v080","title":"Important Notes for v0.8.0","text":""},{"location":"config/#setting-a-key-in-config-no-longer-breaks-offline-test-mode","title":"\u2714 Setting a key in config no longer breaks offline test mode","text":"<p>Tests that expect offline behavior should unset GOOGLE_API_KEY.</p>"},{"location":"config/#config-file-is-optional","title":"\u2714 Config file is optional","text":"<p>If no config file exists, it will be created on first set-key or set-model command.</p>"},{"location":"config/#key-is-not-required-for-code-generation","title":"\u2714 Key is not required for code generation","text":"<p>agent gen widget ... works even without a key.</p>"},{"location":"errors/","title":"Error Handling","text":"<p>The Multimodal Agent uses a unified error model based on the AgentError class. All user-facing errors are clean, predictable, and safe to catch.</p> <p>This document explains: -   What errors the system raises -   When they occur -   How to handle them -   How errors differ between online mode and offline fake mode</p>"},{"location":"errors/#base-error-class","title":"Base Error Class","text":"<p>All agent errors inherit from: <pre><code>from multimodal_agent.errors import AgentError\n</code></pre></p> <p>You can catch all domain-specific exceptions via: <pre><code>try:\n    agent.ask(\"Hello\")\nexcept AgentError as e:\n    print(\"Agent failed:\", e)\n</code></pre> This ensures your application never receives raw API exceptions.</p>"},{"location":"errors/#types-of-errors","title":"Types of Errors","text":"<p>The following are common error categories.</p>"},{"location":"errors/#json-parsing-errors","title":"JSON Parsing Errors","text":"<p>Raised when the model does not return valid JSON: <pre><code>result = agent.ask(\"Give JSON\", response_format=\"json\")\n</code></pre> If the model returns invalid JSON, you get: <pre><code>AgentError: Failed to parse JSON output\n</code></pre></p> <p>Fix:</p> <p>Improve prompt constraints or reduce creativity; JSON mode requires strict formatting.</p>"},{"location":"errors/#code-generation-validation-errors","title":"Code Generation Validation Errors","text":"<p>When using the CLI: <pre><code>agent gen widget HomeScreen\n</code></pre></p> <p>The system validates that the generated code: -   Contains the expected class -   Has no Markdown -   Starts with imports/class definitions</p> <p>If validation fails, you\u2019ll see: <pre><code>ValueError: Generated code does not contain class `HomeScreen`.\n</code></pre></p> <p>This typically means the LLM was too creative. The built-in prompts are designed to reduce this.</p> <p>\u2e3b</p>"},{"location":"errors/#project-root-file-system-errors","title":"Project Root &amp; File System Errors","text":"<p>If a Flutter project root is not detected: <pre><code>FileNotFoundError: Could not find pubspec.yaml in any parent directory.\n</code></pre></p> <p>Fix: Run agent gen inside a Flutter project or provide a valid path.</p> <p>\u2e3b</p>"},{"location":"errors/#offline-fake-mode-errors","title":"Offline Fake Mode Errors","text":"<p>When no API key exists (GOOGLE_API_KEY=\"\"), the agent switches to fake mode, which: -   Never calls external APIs -   Returns deterministic stub responses -   Never raises network or API errors</p> <p>Example fake response: <pre><code>FAKE_RESPONSE: hello\n</code></pre></p> <p>JSON mode produces: <pre><code>{\"message\": \"hello\"}\n</code></pre></p> <p>Useful for CI, unit tests, and offline work.</p>"},{"location":"errors/#image-errors","title":"Image Errors","text":"<p>When reading images: <pre><code>Error: could not load image.\n</code></pre></p> <p>This appears if the file is missing or unreadable. The CLI logs details but prints a friendly error.</p> <p>\u2e3b</p>"},{"location":"errors/#rag-store-errors","title":"RAG Store Errors","text":"<p>SQLite-based RAG may raise: -   Database locked -   Invalid chunk -   Corrupt DB file</p> <p>The CLI prints helpful guidance: <pre><code>Error: RAG storage failure. Try resetting the database.\n</code></pre></p> <p>The DB path can be reset by deleting: <pre><code>rm -f ~/.multimodal_agent/memory.db\n</code></pre></p>"},{"location":"errors/#server-errors","title":"Server Errors","text":"<p>Running: <pre><code>agent server\n</code></pre></p> <p>Common issues:</p> Error Meaning Port in use Try another port with --port Missing models Ensure config is correct Startup timeout Slow environment or blocked port"},{"location":"errors/#quota-rate-limit-errors-429-resource_exhausted","title":"Quota / Rate Limit Errors (429 RESOURCE_EXHAUSTED)","text":"<p>When using the Gemini API free tier, you may encounter:</p> <p><pre><code>429 RESOURCE_EXHAUSTED\nQuota exceeded\n</code></pre> This is expected behavior, not a Multimodal Agent bug.</p> <p>Causes: -   Daily request limit reached -   Requests-per-minute (RPM) exceeded -   Token quota exhausted</p> <p>Behavior: -   CLI: error wrapped in AgentError -   Server: returns HTTP 429 -   VS Code extension: shows a notification error</p> <p>Solutions: -   Wait for quota reset (usually within 24 hours) -   Reduce request frequency -   Switch to a lighter model (e.g. flash \u2192 flash-lite when available) -   Upgrade your Gemini API plan</p> <p>While quota is exhausted, offline fake mode and local tests continue to work.</p>"},{"location":"errors/#model-not-found-errors-404-not_found","title":"Model Not Found Errors (404 NOT_FOUND)","text":"<p>Raised when a configured Gemini model does not exist or is deprecated.</p> <p>Example: <pre><code>404 NOT_FOUND: models/gemini-1.5-pro is not supported\n</code></pre></p> <p>Common causes: -   Using deprecated models (e.g. gemini-1.5-pro) -   Typos in model name -   Config file out of sync with Gemini API</p> <p>Fix: -   Update chat_model / image_model in config -   Restart the agent server -   Verify available models at: https://ai.google.dev/gemini-api/docs/models</p> <p>Note: The CLI may continue working while the server or VS Code extension fails due to stricter timeouts and quota enforcement.</p>"},{"location":"errors/#logging-and-debug-mode","title":"Logging and Debug Mode","text":"<p>Set debug mode: <pre><code>agent --debug ask \"Hello\"\n</code></pre></p> <p>This prints: -   Internal exceptions -   Prompt size -   Token usage details -   RAG retrievals</p> <p>Useful for diagnosing pipeline issues.</p>"},{"location":"errors/#best-practices-for-error-handling","title":"Best Practices for Error Handling","text":""},{"location":"errors/#always-wrap-external-calls","title":"Always wrap external calls","text":"<pre><code>try:\n    response = agent.ask(\"Hello\")\nexcept AgentError as e:\n    log.error(f\"Agent failed: {e}\")\n</code></pre>"},{"location":"errors/#validate-json-before-using-it","title":"Validate JSON before using it","text":"<pre><code>data = response.data\nif not data:\n    raise ValueError(\"Model returned empty JSON payload\")\n</code></pre>"},{"location":"errors/#validate-codegen-output-when-using-the-library-programmatically","title":"Validate codegen output when using the library programmatically","text":"<pre><code>code = agent.ask(prompt).text\nif \"class \" not in code:\n    raise AgentError(\"Invalid Dart code\")\n</code></pre>"},{"location":"errors/#expected-behavior-summary","title":"Expected Behavior Summary","text":"Scenario Behavior Missing API key Fake-mode, no exceptions Invalid JSON AgentError Missing image User-friendly error message Codegen class mismatch ValueError RAG DB issues AgentError Model API failure Wrapped in AgentError CLI misuse Argparse prints help Quota exceeded (429) AgentError / HTTP 429 Model not found (404) AgentError / HTTP 400"},{"location":"errors/#raising-custom-errors","title":"Raising Custom Errors","text":"<p>You can raise agent errors manually: <pre><code>from multimodal_agent.errors import AgentError\n\nraise AgentError(\"Something went wrong\")\n</code></pre></p>"},{"location":"errors/#when-to-report-an-issue","title":"When to Report an Issue","text":"<p>Open a GitHub issue if you see: -   Inconsistent validation behavior -   Unexpected offline-mode behavior -   CLI silently failing -   RAG memory corruption -   Codegen hallucinations beyond prompt constraints</p>"},{"location":"examples/","title":"Code Examples","text":"<p>This page provides small, practical examples showing how to use the Multimodal-Agent via Python API, CLI, image queries, RAG, and Flutter code generation (v0.8.0+).</p>"},{"location":"examples/#simple-text-request","title":"Simple Text Request","text":"<pre><code>from multimodal_agent import MultiModalAgent\n\nagent = MultiModalAgent()\n\nresp = agent.ask(\"Explain state management in Flutter.\")\nprint(resp.text)\n</code></pre>"},{"location":"examples/#json-mode","title":"JSON Mode","text":"<pre><code>resp = agent.ask(\"return a small object\", response_format=\"json\")\nprint(resp.data)\n</code></pre> <p>Output: <pre><code>{\n  \"title\": \"Example\",\n  \"value\": 42\n}\n</code></pre></p>"},{"location":"examples/#image-text-queries","title":"Image + Text Queries","text":"<pre><code>from multimodal_agent.utils import load_image_as_part\n\nagent = MultiModalAgent()\n\nimage = load_image_as_part(\"cat.jpg\")\nresp = agent.ask_with_image(\"What do you see?\", image)\n\nprint(resp.text)\n</code></pre>"},{"location":"examples/#rag-adding-messages-manually","title":"RAG: Adding Messages Manually","text":"<p><pre><code>agent.rag_store.add_logical_message(\n    content=\"This project uses Riverpod for state management\",\n    role=\"note\",\n    session_id=\"flutter-app\",\n    source=\"manual\"\n)\n</code></pre> Query using memory: <pre><code>resp = agent.ask(\"What state management do we use?\")\nprint(resp.text)\n</code></pre></p>"},{"location":"examples/#cli-examples","title":"CLI Examples","text":"<p>Ask a question <pre><code>agent ask \"What is dependency injection?\"\n</code></pre></p> <p>Ask with JSON mode <pre><code>agent ask \"give sample json\" --json\n</code></pre></p> <p>Ask with an image <pre><code>agent image photo.png \"describe this\"\n</code></pre></p> <p>Interactive chat <pre><code>agent chat\n</code></pre></p>"},{"location":"examples/#flutter-code-generation-v080","title":"Flutter Code Generation (v0.8.0)","text":"<p>Generate a stateless widget <pre><code>agent gen widget UserCard\n</code></pre></p> <p>Produces: <pre><code>lib/widgets/user_card.dart\n</code></pre></p> <p>Generate a stateful widget <pre><code>agent gen widget Counter --stateful\n</code></pre></p> <p>Generate a screen <pre><code>agent gen screen HomeScreen\n</code></pre></p> <p>Generate a Dart model <pre><code>agent gen model UserProfile\n</code></pre></p> <p>Use --override to overwrite: <pre><code>agent gen widget UserCard --override\n</code></pre></p>"},{"location":"examples/#project-learning-example","title":"Project Learning Example","text":"<pre><code>agent learn-project my_flutter_app/\n</code></pre> <p>Load profile again: <pre><code>agent show-project project:my_flutter_app\n</code></pre></p>"},{"location":"examples/#offline-mode-example","title":"Offline Mode Example","text":"<p>If your environment has no API key, the agent returns deterministic fake responses: <pre><code>unset GOOGLE_API_KEY\nagent ask \"hello\"\n</code></pre></p> <p>Output: <pre><code>FAKE_RESPONSE: hello\n</code></pre></p> <p>Useful for: -   CI pipelines -   Local tests -   Environments without network</p>"},{"location":"examples/#fastapi-server-example","title":"FastAPI Server Example","text":"<p>Run server: <pre><code>agent server --port 9000\n</code></pre></p> <p>Query: <pre><code>curl -X POST http://localhost:9000/generate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"prompt\": \"hello\"}'\n</code></pre></p>"},{"location":"examples/#full-minimal-python-script","title":"Full Minimal Python Script","text":"<pre><code>from multimodal_agent import MultiModalAgent\n\nagent = MultiModalAgent(model=\"gemini-2.5-flash\")\n\nresp = agent.ask(\"Summarize Flutter architecture.\")\nprint(resp.text)\n\nresp = agent.ask(\"give json\", response_format=\"json\")\nprint(resp.data)\n\nimg = load_image_as_part(\"ui.png\")\nresp = agent.ask_with_image(\"Describe this UI\", img)\nprint(resp.text)\n</code></pre>"},{"location":"history/","title":"History Management","text":"<p>The Multimodal-Agent includes a built-in RAG memory system backed by SQLite. All queries can optionally write messages to memory, and you can inspect, filter, or clear history directly from the CLI.</p> <p>History is grouped by session IDs. If you do not provide a session ID, the agent uses a default session.</p>"},{"location":"history/#viewing-history","title":"Viewing History","text":"<p>Show recent memory entries:</p> <pre><code>agent history show\n</code></pre> <p>Limit the number of entries: <pre><code>agent history show --limit 20\n</code></pre> Filter by session: <pre><code>agent history show --session my-app\n</code></pre></p> <p>Hide noisy internal messages (FAKE_RESPONSE, project profiles, tests):</p> <pre><code>agent history show --clean\n</code></pre>"},{"location":"history/#clearing-history","title":"Clearing History","text":"<p>Clear all entries: <pre><code>agent history clear\n</code></pre> Clear entries for a specific session: <pre><code>agent history clear --session my-app\n</code></pre></p>"},{"location":"history/#deleting-a-specific-chunk","title":"Deleting a Specific Chunk","text":"<p>Each memory item has a numeric ID. To delete one: <pre><code>agent history delete 42\n</code></pre></p>"},{"location":"history/#summarizing-memory","title":"Summarizing Memory","text":"<p>The agent can summarize memory using the current chat model: <pre><code>agent history summary --limit 50\n</code></pre></p> <p>Or for a specific session: <pre><code>agent history summary --session my-app\n</code></pre> The summary is generated using AI but is never stored automatically\u2014you\u2019re in control.</p>"},{"location":"history/#how-history-works-internally","title":"How History Works Internally","text":"<ul> <li> <p>History is stored inside a SQLite database: <pre><code>~/.multimodal_agent/memory.db\n</code></pre></p> </li> <li> <p>Each message is stored with:</p> <ul> <li>content</li> <li>role (\u201cuser\u201d, \u201cassistant\u201d, \u201cnote\u201d, etc.)</li> <li>session_id</li> <li>source (CLI, project-learning, test, etc.)</li> <li>timestamp</li> <li>Text queries (agent ask) and chat sessions store content unless --no-rag is used.</li> <li>Image queries also store text fragments derived from the description.</li> </ul> </li> </ul>"},{"location":"history/#disabling-rag-history","title":"Disabling RAG / History","text":"<p>You can disable memory for a single query: <pre><code>agent ask \"What is DI?\" --no-rag\n</code></pre></p> <p>Or start a chat without memory: <pre><code>agent chat --no-rag\n</code></pre></p>"},{"location":"history/#writing-notes-manually","title":"Writing Notes Manually","text":"<p>You can manually insert notes into memory using Python: <pre><code>from multimodal_agent import MultiModalAgent\n\nagent = MultiModalAgent()\nagent.rag_store.add_logical_message(\n    content=\"This project uses Riverpod.\",\n    role=\"note\",\n    session_id=\"flutter-app\",\n    source=\"manual\"\n)\n</code></pre></p>"},{"location":"history/#project-learning-v060","title":"Project Learning (v0.6.0+)","text":"<p>The learn-project command scans source code and saves a structured project profile into memory. <pre><code>agent learn-project my_flutter_app/\n</code></pre> Then retrieve: <pre><code>agent show-project project:my_flutter_app\n</code></pre></p> <p>Project learning integrates seamlessly with history and improves the model\u2019s responses.</p>"},{"location":"installation/","title":"Installation","text":"<p>Multimodal-Agent is a lightweight wrapper around Google Gemini with support for RAG, multimodal input (text + image), and Flutter code generation.</p> <p>This guide explains how to install and configure the library.</p>"},{"location":"installation/#install-via-pip","title":"Install via pip","text":"<p><pre><code>pip install multimodal-agent\n</code></pre> To upgrade: <pre><code>pip install -U multimodal-agent\n</code></pre></p>"},{"location":"installation/#install-from-source","title":"Install from source","text":"<pre><code>git clone https://github.com/horam/multimodal-agent.git\ncd multimodal-agent\npip install -e .[dev,test]\n</code></pre>"},{"location":"installation/#set-up-your-api-key","title":"Set up your API key","text":"<p>Multimodal-Agent automatically loads keys from:</p> <ul> <li>environment variable</li> <li>.env file in project root</li> <li>agent config set-key</li> </ul> <p>Option A \u2014 Environment variable</p> <pre><code>export GOOGLE_API_KEY=\"your-key-here\"\n</code></pre> <p>Option B \u2014 .env file (recommended for local projects)</p> <p>Create: <pre><code>.env\n</code></pre></p> <p>Inside: <pre><code>GOOGLE_API_KEY=your-key-here\n</code></pre></p>"},{"location":"installation/#offline-fake-mode-no-api-key","title":"Offline Fake Mode (no API key)","text":"<p>If no key is provided the agent still works, using predictable fake responses. <pre><code>from multimodal_agent.core.agent_core import MultiModalAgent\n\nagent = MultiModalAgent()\nprint(agent.ask(\"hello\").text) # -&gt; FAKE_RESPONSE: hello\n</code></pre></p> <p>This is ideal for: -   testing -   CI pipelines -   environments without network access</p>"},{"location":"installation/#additional-optional-dependencies","title":"Additional Optional Dependencies","text":"<p>Some features require additional tools:</p> <p>RAG (SQLite-based)</p> <p>No extra installation needed \u2014 SQLite is built-in.</p> <p>FastAPI Server</p> <p>If you want server mode: <pre><code>pip install multimodal-agent[server]\n</code></pre></p> <p>Documentation generation (for maintainers) <pre><code>pip install multimodal-agent[dev]\n</code></pre></p>"},{"location":"installation/#flutter-code-generation-requirements-v080","title":"Flutter Code Generation Requirements (v0.8.0+)","text":"<p>To generate widgets, screens, and models, the CLI must run inside a valid Flutter project root (one containing a pubspec.yaml).</p> <p>Example: <pre><code>cd my_flutter_app\nagent gen widget CoolWidget\n</code></pre></p> <p>Generated files are placed automatically: <pre><code>lib/widgets/\nlib/screens/\nlib/models/\n</code></pre></p>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<p><pre><code>agent --version\n</code></pre> Expected output: <pre><code>multimodal-agent version 0.8.0\n</code></pre></p> <p>Test API access: <pre><code>agent ask \"hello\"\n</code></pre></p> <p>If key is missing, you will see: <pre><code>FAKE_RESPONSE: hello\n</code></pre></p>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":"<p>\u201cCould not find pubspec.yaml\u201d</p> <p>Move into your Flutter project directory: <pre><code>cd path/to/app\n</code></pre></p> <p>\u201cNo such file or directory: image\u201d</p> <p>Ensure the image exists before using: <pre><code>agent image ./photo.png \"describe\"\n</code></pre></p> <p>\u201cInvalid API key\u201d</p> <p>Check: <pre><code>echo $GOOGLE_API_KEY\n</code></pre></p>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<p>Continue with: -   CLI Usage\ufffc -   Quickstart Tutorial\ufffc -   RAG System\ufffc</p>"},{"location":"json_mode/","title":"JSON Mode (response_format=\"json\")","text":"<p>The Multimodal Agent supports strict JSON responses using either: -   the Python API, or -   the CLI flag --json</p> <p>JSON mode ensures that structured outputs are: -   Valid JSON (strictly parseable) -   Returned through AgentResponse.data -   Mirrored as a JSON string in AgentResponse.text</p> <p>This is strongly recommended for tool output, structured reasoning, and integration workflows.</p>"},{"location":"json_mode/#enabling-json-mode","title":"Enabling JSON Mode","text":""},{"location":"json_mode/#python-api","title":"Python API","text":"<p><pre><code>from multimodal_agent.core.agent_core import MultiModalAgent\nagent = MultiModalAgent()\n\nresult = agent.ask(\"Give me a JSON object\", response_format=\"json\")\nprint(result.data)\n</code></pre> Result Structure <pre><code>AgentResponse(\n    text='{\"weather\":\"sunny\"}',\n    data={\"weather\": \"sunny\"},\n    usage={...}\n)\n</code></pre></p> <ul> <li>text: raw JSON string returned by the model</li> <li>data: parsed Python dictionary</li> <li>usage: token usage metadata</li> </ul>"},{"location":"json_mode/#cli-mode","title":"CLI Mode","text":"<pre><code>agent ask \"Describe your system as JSON\" --json\n</code></pre> <p>Output Example <pre><code>{\n  \"weather\": \"sunny\",\n  \"temperature\": 28\n}\n</code></pre></p>"},{"location":"json_mode/#json-mode-in-offline-fake-mode","title":"JSON Mode in Offline Fake Mode","text":"<p>If no API key is set, the agent enters fake mode: <pre><code>export GOOGLE_API_KEY=\"\"\n</code></pre></p> <p>In fake mode:</p> <p>Request <pre><code>agent.ask(\"hello\", response_format=\"json\")\n</code></pre></p> <p>Output <pre><code>AgentResponse(\n    text='{\"message\": \"hello\"}',\n    data={\"message\": \"hello\"},\n)\n</code></pre></p> <p>Important change in v0.8.x:</p> <p>\u2714 data is now a dict, not None</p> <p>\u2714 JSON behavior is consistent in online/offline mode</p> <p>\u2714 Tests expect .data to contain the parsed JSON</p> <p>This simplifies testing and keeps the model behavior stable.</p>"},{"location":"json_mode/#behavior-guarantees","title":"Behavior Guarantees","text":"<p>\u2714 Always returns valid JSON</p> <p>The agent will retry, repair, and normalize the model output.</p> <p>\u2714 No markdown or prose allowed</p> <p>Prompts automatically enforce: <pre><code>Output ONLY valid JSON. No commentary.\n</code></pre></p> <p>\u2714 If JSON cannot be parsed \u2192 raises AgentError</p> <p>Example: <pre><code>AgentError: Failed to parse JSON output:\n&lt;raw model output&gt;\n</code></pre></p>"},{"location":"json_mode/#common-use-cases","title":"Common Use Cases","text":""},{"location":"json_mode/#structured-information-extraction","title":"Structured Information Extraction","text":"<p><pre><code>agent.ask(\n    \"Extract name and age.\",\n    response_format=\"json\"\n)\n</code></pre> <pre><code>{\"name\": \"Alice\", \"age\": 32}\n</code></pre></p>"},{"location":"json_mode/#tool-invocation-function-arguments","title":"Tool Invocation &amp; Function Arguments","text":"<p>JSON mode allows the agent to be used as a semantic parser.</p>"},{"location":"json_mode/#integration-with-frontend-mobile-apps","title":"Integration With Frontend / Mobile Apps","text":"<p>Dart, React, and Flutter consumers benefit from predictable structured output: <pre><code>{\"title\": \"Hello\", \"count\": 3}\n</code></pre></p>"},{"location":"json_mode/#error-handling","title":"Error Handling","text":"<p>Invalid JSON</p> <p>If the model returns malformed JSON: <pre><code>AgentError: Failed to parse JSON output\n</code></pre></p> <p>Offline Fake Mode Always Succeeds</p> <p>Guaranteed output: <pre><code>{\"message\": \"your_prompt_here\"}\n</code></pre></p> <p>Useful for: -   CI pipelines -   Local unit tests -   Environments without internet</p> <p>\u2e3b</p>"},{"location":"json_mode/#accessing-json-results","title":"Accessing JSON Results","text":"<p>Python API <pre><code>data = result.data     # dict\nraw = result.text      # JSON string\n</code></pre> CLI</p> <p>Output is printed as clean JSON: <pre><code>agent ask \"hi\" --json\n</code></pre></p>"},{"location":"json_mode/#best-practices","title":"Best Practices","text":"<p>\u2714 Always validate required fields: <pre><code>if \"name\" not in result.data:\n    raise ValueError(\"Missing required field: name\")\n</code></pre> \u2714 Design prompts like this: <pre><code>Return ONLY valid JSON with fields: name, age, city.\n</code></pre></p> <p>\u2714 Avoid natural language in JSON mode prompts.</p> <p>\u2714 For complex schemas, include a template: <pre><code>Provide JSON with this structure:\n{\n  \"title\": \"\",\n  \"items\": []\n}\n</code></pre></p>"},{"location":"json_mode/#summary-table","title":"Summary Table","text":"Mode text data JSON mode (online) Raw JSON Parsed dict JSON mode (offline/fake) JSON string Parsed dict Text mode Text/string None"},{"location":"logging/","title":"Logging System","text":"<p>The Multimodal Agent uses a structured and consistent logging framework built around Python\u2019s logging module. Logging supports:</p> <ul> <li>Debugging during development</li> <li>Tracking model behavior</li> <li>Monitoring RAG interactions</li> <li>Inspecting code generation flow (new in v0.8.x)</li> </ul> <p>All logs are routed through the centralized helper:</p> <pre><code>multimodal_agent.logger.get_logger(name)\n</code></pre>"},{"location":"logging/#log-levels","title":"Log Levels","text":"<p>The agent respects the environment variable:</p> <pre><code>export LOGLEVEL=DEBUG\n</code></pre> <p>Or CLI flag:</p> <pre><code>agent --debug\n</code></pre>"},{"location":"logging/#supported-levels","title":"Supported levels:","text":"Level Description DEBUG Verbose internal details (RAG queries, retries, sanitization) INFO High-level behavior (initialization, file generation) WARNING Recoverable problems ERROR Failures during model calls or generation CRITICAL Rare, system-level failures"},{"location":"logging/#where-logging-occurs","title":"Where Logging Occurs","text":""},{"location":"logging/#agent-core-agent_corepy","title":"Agent Core (agent_core.py)","text":"<p>Logs include:</p> <ul> <li>Agent initialization</li> <li>Whether offline fake mode was triggered</li> <li>Retry/backoff cycles</li> <li>JSON parsing attempts</li> <li>RAG lookup status</li> </ul> <p>Example:</p> <pre><code>[INFO] Initializing MultiModal agent...\n[DEBUG] No API key found \u2192 entering offline FAKE mode.\n</code></pre>"},{"location":"logging/#rag-system-rag_storepy","title":"RAG System (rag_store.py)","text":"<p>Logs include:</p> <ul> <li>Writing content to SQLite</li> <li>Normalization of chunks</li> <li>Loading/merging histories</li> <li>Project-profile operations</li> </ul> <p>Example:</p> <pre><code>[DEBUG] Stored chunk id=182 in session=project:app\n</code></pre>"},{"location":"logging/#cli-clipy","title":"CLI (cli.py)","text":"<p>Logs include:</p> <ul> <li>Command dispatching</li> <li>Error messages</li> <li>Codegen generation path</li> </ul> <p>Example:</p> <pre><code>[INFO] Widget generated at /lib/widgets/home_screen.dart\n</code></pre>"},{"location":"logging/#code-generation-engine-codegenenginepy","title":"Code Generation Engine (codegen/engine.py)","text":"<p>New in v0.8.x, logs capture:</p> <ul> <li>Sanitized class names</li> <li>Prompt construction</li> <li>Extraction of code blocks</li> <li>Validation failures (missing class name, missing import)</li> </ul> <p>Example:</p> <pre><code>[DEBUG] Expected class: HomeScreen, found in output: True\n</code></pre>"},{"location":"logging/#enabling-debug-mode","title":"Enabling Debug Mode","text":""},{"location":"logging/#cli","title":"CLI","text":"<pre><code>agent --debug ask \"hello\"\n</code></pre>"},{"location":"logging/#python","title":"Python","text":"<pre><code>import os\nos.environ[\"LOGLEVEL\"] = \"DEBUG\"\n\nagent = MultiModalAgent()\nagent.ask(\"hello\")\n</code></pre>"},{"location":"logging/#offline-mode-logging","title":"Offline Mode Logging","text":"<p>When no API key is provided (GOOGLE_API_KEY=\"\"), the agent logs:</p> <pre><code>[DEBUG] Fake-mode active: returning deterministic mock response.\n</code></pre> <p>Fake-mode logs also suppress unnecessary noise to keep unit-test output clean.</p>"},{"location":"logging/#logging-in-server-mode","title":"Logging in Server Mode","text":"<p>When running:</p> <pre><code>agent server\n</code></pre> <p>Logging integrates with Uvicorn.</p> <p>Debug mode can be enabled:</p> <pre><code>agent --debug server\n</code></pre> <p>Or:</p> <pre><code>export LOGLEVEL=DEBUG\nuvicorn ...\n</code></pre> <p>Server logs include:</p> <ul> <li>Request metadata</li> <li>Inference timing</li> <li>Error responses with structured JSON</li> </ul>"},{"location":"logging/#integration-notes","title":"Integration Notes","text":""},{"location":"logging/#best-practices","title":"Best practices:","text":"<ul> <li>Use DEBUG during development</li> <li>Use INFO in production environments</li> <li>Avoid writing sensitive content to logs</li> <li>For security, RAG text is never logged verbatim unless DEBUG is enabled</li> </ul>"},{"location":"logging/#future-improvements","title":"Future Improvements","text":"<p>Logging roadmap:</p> <ul> <li>Structured logs in JSON format</li> <li>Log rotation</li> <li>Rich debug dashboard in VS Code extension</li> <li>Model latency + token cost analytics</li> </ul>"},{"location":"memory/","title":"Memory System (RAG Memory)","text":"<p>The memory system is a lightweight Retrieval-Augmented-Generation (RAG) layer built on top of a persistent SQLite database.</p> <p>Every interaction with the agent can be stored, retrieved, summarized, or cleared.</p> <p>Memory is used by the agent to:</p> <ul> <li>Maintain context across conversations</li> <li>Retrieve relevant past answers</li> <li>Store project profiles (via agent learn-project)</li> <li>Improve long chats without sending long prompts</li> <li>Provide stable behavior between CLI calls and sessions</li> </ul>"},{"location":"memory/#overview","title":"Overview","text":"<p>The memory system has three core components:</p>"},{"location":"memory/#sqliteragstore","title":"SQLiteRAGStore","text":"<p>A simple, fast, file-based persistence layer located at:</p> <pre><code>~/.multimodal_agent/memory.db\n</code></pre> <p>Controls:</p> <ul> <li>Insert memory chunks</li> <li>Query by session</li> <li>Query by semantic search (planned)</li> <li>Store project profiles</li> <li>Clear or delete entries</li> </ul>"},{"location":"memory/#memory-chunk-format","title":"Memory Chunk Format","text":"<p>Each memory entry is saved with the following schema:</p> Column Description id Unique identifier content Raw text stored role \"user\",\"assistant\",\"system\",\"project_profile\" session_id Logical session grouping created_at Timestamp source \"chat\",\"ask\",\"project-learning\",\"test\", etc. <p>Example JSON block stored inside the chunk:</p> <pre><code>{\n  \"type\": \"message\",\n  \"content\": \"How do I format code?\",\n  \"role\": \"user\"\n}\n</code></pre>"},{"location":"memory/#integration-with-the-agent","title":"Integration with the Agent","text":"<p>Memory is automatically used in:</p> <ul> <li>agent chat</li> <li>agent ask (unless * --no-rag* used)</li> <li>Project learning (agent learn-project)</li> </ul> <p>When enabled, the agent retrieves the most recent and clean memory chunks and includes them before generating a response.</p>"},{"location":"memory/#how-memory-is-used-during-a-query","title":"How Memory Is Used During a Query","text":""},{"location":"memory/#user-makes-request","title":"User makes request","text":"<p>\u2192 The agent checks whether RAG is enabled.</p>"},{"location":"memory/#if-enabled","title":"If enabled","text":"<p>\u2192 Retrieves the most relevant recent memory chunks.</p> <p>\u2192 Adds them to the model input.</p>"},{"location":"memory/#after-producing-an-answer","title":"After producing an answer","text":"<p>\u2192 The agent stores the interaction:</p> <pre><code>role=user   \u2192 content=prompt\nrole=assistant \u2192 text=response\n</code></pre>"},{"location":"memory/#memory-grows-over-time","title":"Memory grows over time","text":"<p>The agent becomes context-aware across sessions and CLI calls.</p>"},{"location":"memory/#session-based-memory","title":"Session-Based Memory","text":"<p>Every interaction can be associated with a session ID:</p> <pre><code>agent chat --session my-app\nagent ask \"Hello\" --session design-docs\n</code></pre> <p>If no session is given:</p> <ul> <li>agent ask uses a stateless ephemeral session</li> <li>agent chat creates or resumes a session automatically</li> </ul> <p>This avoids cross-contamination between unrelated tasks.</p>"},{"location":"memory/#managing-memory","title":"Managing Memory","text":"<p>The CLI provides several tools:</p>"},{"location":"memory/#show-memory","title":"Show Memory","text":"<pre><code>agent history show\n</code></pre> <p>Options:</p> <pre><code>--limit 100\n--session my-session\n--clean          # hides noise: FAKE_RESPONSE, tests, profiles\n</code></pre>"},{"location":"memory/#clear-all-memory","title":"Clear All Memory","text":"<pre><code>agent history clear\n</code></pre> <p>This wipes all memory chunks from the SQLite database.</p>"},{"location":"memory/#delete-a-specific-chunk","title":"Delete a Specific Chunk","text":"<pre><code>agent history delete &lt;chunk_id&gt;\n</code></pre>"},{"location":"memory/#summarize-memory","title":"Summarize Memory","text":"<p>Uses the model to summarize stored chunks:</p> <pre><code>agent history summary --limit 200\n</code></pre>"},{"location":"memory/#project-learning-memory","title":"Project Learning Memory","text":"<p>When you run:</p> <pre><code>agent learn-project /path/to/project\n</code></pre> <p>The tool generates a project profile containing:</p> <ul> <li>package name</li> <li>directories</li> <li>file types</li> <li>dependencies</li> <li>source file summaries</li> <li>semantic markers</li> </ul> <p>This profile is stored in memory using:</p> <pre><code>role = \"project_profile\"\nsource = \"project-learning\"\nsession_id = \"project:&lt;package_name&gt;\"\n</code></pre> <p>You can list stored projects:</p> <pre><code>agent list-projects\n</code></pre> <p>And inspect one:</p> <pre><code>agent show-project my-project-id\n</code></pre>"},{"location":"memory/#offline-mode-interaction","title":"Offline Mode Interaction","text":"<p>If GOOGLE_API_KEY is missing:</p> <ul> <li>the model generates a deterministic FAKE_RESPONSE</li> <li>memory still works</li> <li>no network calls occur</li> </ul> <p>This makes offline testing easy.</p> <p>Memory chunk example in offline mode:</p> <pre><code>{\n  \"type\": \"message\",\n  \"content\": \"FAKE_RESPONSE: test\",\n  \"role\": \"assistant\"\n}\n</code></pre>"},{"location":"memory/#memory-file-location","title":"Memory File Location","text":"<p>On macOS/Linux:</p> <pre><code>~/.multimodal_agent/memory.db\n</code></pre> <p>On Windows:</p> <pre><code>%USERPROFILE%\\.multimodal_agent\\memory.db\n</code></pre> <p>You can override path via environment variable:</p> <pre><code>export MULTIMODAL_AGENT_DB=/custom/path/agent.db\n</code></pre>"},{"location":"memory/#best-practices","title":"Best Practices","text":""},{"location":"memory/#use-sessions-for-large-or-long-term-tasks","title":"Use sessions for large or long-term tasks","text":"<pre><code>agent chat --session flutter-app\n</code></pre>"},{"location":"memory/#clear-memory-when-switching-topics","title":"Clear memory when switching topics","text":"<pre><code>agent history clear\n</code></pre>"},{"location":"memory/#use-project-profiles-for-codebases","title":"Use project profiles for codebases","text":"<pre><code>agent learn-project ./my_flutter_app\n</code></pre>"},{"location":"memory/#use-no-rag-for-pure-llm-answers","title":"Use --no-rag for pure LLM answers","text":"<pre><code>agent ask \"What is 2+2?\" --no-rag\n</code></pre>"},{"location":"metadata_schema/","title":"Response Metadata Schema","text":"<p>Every call to the Multimodal Agent returns an AgentResponse object containing:</p> <ul> <li>text \u2014 the primary output (string)</li> <li>data \u2014 parsed JSON (if response_format=\"json\")</li> <li>usage \u2014 token usage statistics</li> <li>metadata \u2014 optional extended data (future use)</li> <li>raw \u2014 raw model response (only if enabled)</li> </ul> <p>This document defines the schema for these fields.</p>"},{"location":"metadata_schema/#agentresponse-structure","title":"AgentResponse Structure","text":"<p>Python structure:</p> <pre><code>AgentResponse(\n    text: str | None,\n    data: dict | None,\n    usage: dict | None,\n    raw: Any | None = None\n)\n</code></pre> <p>JSON-serializable form:</p> <pre><code>{\n  \"text\": \"...\",\n  \"data\": null,\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"response_tokens\": 45,\n    \"total_tokens\": 168\n  }\n}\n</code></pre>"},{"location":"metadata_schema/#field-definitions","title":"Field Definitions","text":""},{"location":"metadata_schema/#text","title":"text","text":"<p>Primary output returned by:</p> <ul> <li>agent.ask()</li> <li>agent.ask_with_image()</li> <li>CLI (agent ask ...)</li> <li>Code generation</li> <li>Server mode</li> </ul> <p>Behavior by mode:</p> Mode textValue Normal Model-generated string JSON mode Raw JSON string returned by model Offline mode \"FAKE_RESPONSE:<code>&lt;your prompt&gt;</code>\" Image mode Description or multimodal output"},{"location":"metadata_schema/#data","title":"data","text":"<p>Parsed JSON, only populated when:</p> <pre><code>response_format=\"json\"\n</code></pre> <p>Example:</p> <p>Input prompt:</p> <pre><code>agent.ask(\"Return JSON\", response_format=\"json\")\n</code></pre> <p>Response:</p> <pre><code>{\n  \"text\": \"{\\\"message\\\": \\\"hi\\\"}\",\n  \"data\": { \"message\": \"hi\" }\n}\n</code></pre> <p>Offline mode behavior:</p> <p>In ** offline JSON mode , data is:**</p> <pre><code>None\n</code></pre> <p>(because fake mode does not generate JSON)</p>"},{"location":"metadata_schema/#usage","title":"usage","text":"<p>Token usage structure:</p> <pre><code>{\n  \"prompt_tokens\": 91,\n  \"response_tokens\": 23,\n  \"total_tokens\": 114\n}\n</code></pre> <p>Always present except in certain test stubs.</p> <p>See token_usage.md for full detail.</p>"},{"location":"metadata_schema/#raw-optional","title":"raw (optional)","text":"<p>Raw model object, when enabled via:</p> <pre><code>agent = MultiModalAgent(return_raw=True)\n</code></pre> <p>Useful for debugging:</p> <pre><code>print(resp.raw.candidates[0].content)\n</code></pre> <p>Not returned in CLI or server output unless explicitly enabled.</p>"},{"location":"metadata_schema/#image-metadata-schema","title":"Image Metadata Schema","text":"<p>When using:</p> <pre><code>agent.ask_with_image(prompt, load_image_as_part(path))\n</code></pre> <p>The final metadata includes:</p> <pre><code>{\n  \"text\": \"...\",\n  \"usage\": { ... },\n  \"image\": {\n    \"mime_type\": \"image/jpeg\",\n    \"size_bytes\": 104322,\n    \"mode\": \"RGB\"\n  }\n}\n</code></pre> <p>(Only available when return_raw=True or server mode includes metadata.)</p>"},{"location":"metadata_schema/#code-generation-metadata","title":"Code Generation Metadata","text":"<p>For calls such as:</p> <pre><code>agent gen widget HomeScreen\n</code></pre> <p>The model response internally includes:</p> <pre><code>{\n  \"text\": \"&lt;dart code&gt;\",\n  \"usage\": { ... },\n  \"codegen\": {\n    \"class_detected\": \"HomeScreen\",\n    \"validated\": true,\n    \"output_path\": \"lib/widgets/home_screen.dart\"\n  }\n}\n</code></pre> <p>This metadata is currently not exposed to the user, but part of internal planning for v0.9.x.</p>"},{"location":"metadata_schema/#rag-metadata","title":"RAG Metadata","text":"<p>When RAG is enabled:</p> <pre><code>agent = MultiModalAgent(enable_rag=True)\n</code></pre> <p>The internal schema includes:</p> <pre><code>{\n  \"rag\": {\n    \"enabled\": true,\n    \"retrieved_chunks\": 3,\n    \"tokens_added\": 428,\n    \"session_id\": \"abc123\"\n  }\n}\n</code></pre> <p>This metadata is not shown unless debugging hooks are activated.</p>"},{"location":"metadata_schema/#cli-metadata","title":"CLI Metadata","text":"<p>The CLI prints markdown with metadata sections:</p> <pre><code>### Question\n...\n\n### Answer\n...\n\n---\ntype: ask\ncommand: ask\n</code></pre> <p>No internal fields (like raw model metadata) are shown.</p>"},{"location":"metadata_schema/#server-mode-schema","title":"Server Mode Schema","text":"<p>The FastAPI server returns:</p> <pre><code>{\n  \"text\": \"...\",\n  \"data\": null,\n  \"usage\": {\n    \"prompt_tokens\": 88,\n    \"response_tokens\": 31,\n    \"total_tokens\": 119\n  }\n}\n</code></pre> <p>Future versions may include:</p> <ul> <li>latency_ms</li> <li>model_name</li> <li>rag block</li> </ul>"},{"location":"metadata_schema/#offline-mode-schema","title":"Offline Mode Schema","text":"<p>When no GOOGLE_API_KEY is present:</p> <pre><code>{\n  \"text\": \"FAKE_RESPONSE: hello\",\n  \"data\": null,\n  \"usage\": {\n    \"prompt_tokens\": 5,\n    \"response_tokens\": 5,\n    \"total_tokens\": 10\n  }\n}\n</code></pre> <p>Format is always preserved.</p> <p>Useful for deterministic test runs.</p>"},{"location":"metadata_schema/#planned-extensions-v09x","title":"Planned Extensions (v0.9.x)","text":"<p>New metadata fields expected:</p> <ul> <li>source: \"text\" | \"image\" | \"codegen\"</li> <li>latency_ms: end-to-end latency</li> <li>prompt_preview: first 200 chars of formatted prompt</li> <li>rag_context_preview: snippets of retrieved chunks</li> <li>safety_attributes: Gemini safety metadata</li> </ul>"},{"location":"quickstart/","title":"Quickstart","text":"<p>Welcome to Multimodal-Agent \u2014 a lightweight, production-ready wrapper around Google Gemini with RAG, CLI tools, and Flutter code generation.</p> <p>This guide helps you get running in under a minute.</p>"},{"location":"quickstart/#install","title":"Install","text":"<p><pre><code>pip install multimodal-agent\n</code></pre> Set your API key: <pre><code>export GOOGLE_API_KEY=\"your-key-here\"\n</code></pre></p> <p>No API key?</p> <p>The library automatically falls back to offline fake mode, returning predictable stub responses for testing and CI.</p>"},{"location":"quickstart/#ask-questions-text","title":"Ask Questions (Text)","text":"<pre><code>agent ask \"Explain reactive programming in Flutter\"\n</code></pre> <p>JSON output: <pre><code>agent ask \"give me a summary\" --json\n</code></pre></p>"},{"location":"quickstart/#ask-with-an-image","title":"Ask With an Image","text":"<pre><code>agent image ./photo.png \"What is shown in this picture?\"\n</code></pre>"},{"location":"quickstart/#start-chat-session","title":"Start Chat Session","text":"<pre><code>agent chat\n</code></pre> <p>Chat sessions preserve context automatically unless disabled: <pre><code>agent chat --no-rag\n</code></pre></p> <p>\u2e3b</p>"},{"location":"quickstart/#generate-flutter-code-v080","title":"Generate Flutter Code (v0.8.0)","text":"<p>Generate a widget <pre><code>agent gen widget CoolWidget\n</code></pre></p> <p>Stateful: <pre><code>agent gen widget CoolCounter --stateful\n</code></pre></p> <p>Generate a screen <pre><code>agent gen screen HomeScreen\n</code></pre></p> <p>Generate a model <pre><code>agent gen model UserProfile\n</code></pre></p> <p>Overwrite existing files: <pre><code>agent gen widget CardItem --override\n</code></pre></p> <p>Files are created inside: <pre><code>lib/widgets/\nlib/screens/\nlib/models/\n</code></pre></p> <p>Class names are automatically sanitized (e.g., 123temp \u2192 W123temp).</p>"},{"location":"quickstart/#use-python-api","title":"Use Python API","text":"<pre><code>from multimodal_agent.core.agent_core import MultiModalAgent\n\nagent = MultiModalAgent()\n\nresponse = agent.ask(\"Explain what a vector database is.\")\nprint(response.text)\n</code></pre> <p>With an image: <pre><code>from multimodal_agent.utils import load_image_as_part\n\nimg = load_image_as_part(\"cat.png\")\nresp = agent.ask_with_image(\"Describe this cat\", img)\nprint(resp.text)\n</code></pre> Offline mode example (no API key): <pre><code>agent = MultiModalAgent()\nresp = agent.ask(\"hello\")\nprint(resp.text)     # \u2192 FAKE_RESPONSE: hello\n</code></pre></p>"},{"location":"quickstart/#inspect-rag-memory","title":"Inspect RAG Memory","text":"<p>Show stored messages: <pre><code>agent history show\n</code></pre> Clear memory: <pre><code>agent history clear\n</code></pre> Summarize history using the model: <pre><code>agent history summary\n</code></pre></p>"},{"location":"quickstart/#run-the-api-server","title":"Run the API Server","text":"<pre><code>agent server --port 8000\n</code></pre> <p>The server exposes endpoints for:     \u2022   text queries     \u2022   image + text     \u2022   project learning     \u2022   metadata inspection</p>"},{"location":"quickstart/#learn-a-project-code-aware-rag","title":"Learn a Project (Code-Aware RAG)","text":"<p><pre><code>agent learn-project ./my_flutter_app\n</code></pre> This stores a structured project profile in the RAG database.</p> <p>List stored projects: <pre><code>agent list-projects\n</code></pre></p>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<pre><code>\u2022   Explore the CLI reference\ufffc\n\u2022   Learn about Flutter code generation\ufffc\n\u2022   Read the Python API guide\ufffc\n</code></pre> <p>\u2e3b</p> <p>You\u2019re ready to use Multimodal-Agent for code generation, RAG, multimodal chat, and AI-assisted development workflows.</p>"},{"location":"rag/","title":"RAG System (Retrieval-Augmented Generation)","text":"<p>The RAG layer in multimodal-agent is designed to be:</p> <ul> <li>Simple (SQLite-based)</li> <li>Fast (local only, no vector DB required)</li> <li>Deterministic (in tests + offline mode)</li> <li>Compatible with Chat, Ask, Image, and Project Learning flows</li> <li>Optional (disable via --no-rag)</li> </ul> <p>RAG helps the agent remember previous interactions, retrieve useful context, and apply project awareness without re-sending long conversation histories to the model.</p>"},{"location":"rag/#purpose-of-rag","title":"Purpose of RAG","text":"<p>RAG is used for:</p>"},{"location":"rag/#injecting-memory-into-prompts","title":"\u2714 Injecting memory into prompts","text":"<p>The agent automatically retrieves recent memory entries and sends them along with your question.</p>"},{"location":"rag/#improving-multi-step-workflows","title":"\u2714 Improving multi-step workflows","text":"<p>Long chats can build up relevant context over time.</p>"},{"location":"rag/#project-level-learning","title":"\u2714 Project-level learning","text":"<p>Using:</p> <pre><code>agent learn-project /path/to/project\n</code></pre> <p>the agent builds a project profile and stores it as a RAG memory block, enabling smarter code analysis and contextual follow-up questions.</p>"},{"location":"rag/#reducing-prompt-size","title":"\u2714 Reducing prompt size","text":"<p>The model only receives the recent and relevant memory entries, not full histories.</p>"},{"location":"rag/#rag-architecture-overview","title":"RAG Architecture Overview","text":"<p>RAG consists of three main components:</p>"},{"location":"rag/#sqliteragstore","title":"SQLiteRAGStore","text":"<p>The persistence layer storing all memory:</p> <pre><code>~/.multimodal_agent/memory.db\n</code></pre> <p>It supports:</p> <ul> <li>add memory chunks</li> <li>list memory chunks</li> <li>retrieve by session</li> <li>store project profiles</li> <li>delete individual chunks</li> <li>clear entire memory</li> </ul> <p>There is currently no vector search \u2014 memory is chronological and relevance-based by session and context.</p>"},{"location":"rag/#memory-chunk-normalizationlightweight","title":"Memory Chunk Normalization(lightweight)","text":"<p>Every memory entry is processed as:</p> <pre><code>{\n  \"type\": \"message\",\n  \"role\": \"user\" | \"assistant\" | \"project_profile\",\n  \"content\": \"...\",\n  \"session_id\": \"some-session\",\n  \"source\": \"chat\" | \"ask\" | \"project-learning\" | \"test\"\n}\n</code></pre> <p>Normalization ensures the agent can use memory consistently regardless of input type.</p>"},{"location":"rag/#rag-injection-layer","title":"RAG Injection Layer","text":"<p>When you call:</p> <pre><code>agent ask \"Explain this code\"\n</code></pre> <p>or</p> <pre><code>agent chat\n</code></pre> <p>The agent:</p> <ol> <li>Loads recent memory (based on session)</li> <li>Filters noise (test content, FAKE_RESPONSE entries, etc.)</li> <li>Produces a context block like:</li> </ol> <pre><code>Previous messages:\n[user] How do I initialize a Flutter widget?\n[assistant] Use const constructors whenever possible.\n\nCurrent message:\n\"Explain this code\"\n</code></pre> <ol> <li>Sends it to the model.</li> </ol> <p>This makes the agent behave like a persistent chat assistant across CLI calls.</p>"},{"location":"rag/#enabling-disabling-rag","title":"Enabling / Disabling RAG","text":""},{"location":"rag/#rag-on-default","title":"RAG ON (default)","text":"<pre><code>agent ask \"hello\"\n</code></pre>"},{"location":"rag/#disable-rag","title":"Disable RAG","text":"<pre><code>agent ask \"hello\" --no-rag\n</code></pre> <p>This completely bypasses memory injection.</p>"},{"location":"rag/#memory-rag-in-chat-mode","title":"Memory + RAG in Chat Mode","text":"<p>Running:</p> <pre><code>agent chat --session demo\n</code></pre> <p>Starts an interactive session that:</p> <ul> <li>loads previous memory for session demo</li> <li>appends new interactions to memory</li> <li>retrieves them in future calls</li> </ul> <p>You can resume that chat later:</p> <pre><code>agent chat --session demo\n</code></pre>"},{"location":"rag/#how-rag-works-with-project-learning","title":"How RAG Works With Project Learning","text":"<p>When you run:</p> <pre><code>agent learn-project my_app/\n</code></pre> <p>The system:</p> <ol> <li>Scans the entire project directory</li> <li>Builds a structured project profile</li> <li>Stores it as RAG memory:</li> </ol> <pre><code>role = project_profile\nsession_id = \"project:&lt;package_name&gt;\"\nsource = project-learning\n</code></pre> <p>You can inspect stored projects:</p> <pre><code>agent list-projects\n</code></pre> <p>Or retrieve a profile:</p> <pre><code>agent show-project my_project\n</code></pre> <p>During code generation (agent gen widget / screen / model), this project knowledge is used IF the agent is model-driven (not stubbed in tests).</p>"},{"location":"rag/#rag-in-offline-mode","title":"RAG in Offline Mode","text":"<p>When GOOGLE_API_KEY is missing:</p> <ul> <li>The agent enters offline fake mode</li> <li>RAG memory still works</li> <li>Model returns deterministic FAKE_RESPONSE</li> </ul> <p>This allows full offline testing of the RAG subsystem.</p> <p>Example stored chunk:</p> <pre><code>{\n  \"role\": \"assistant\",\n  \"content\": \"FAKE_RESPONSE: test\",\n  \"source\": \"ask\"\n}\n</code></pre>"},{"location":"rag/#database-location","title":"Database Location","text":"<p>Default path:</p> <pre><code>~/.multimodal_agent/memory.db\n</code></pre> <p>Override it:</p> <pre><code>export MULTIMODAL_AGENT_DB=/custom/path/memory.db\n</code></pre>"},{"location":"rag/#planned-enhancements-v09","title":"Planned Enhancements (v0.9+)","text":"<ul> <li> <p>Vector search (Lite model)</p> </li> <li> <p>Relevance scoring instead of chronological retrieval</p> </li> <li> <p>Project-level embeddings</p> </li> <li> <p>Query-aware memory selection</p> </li> </ul>"},{"location":"rag/#summary","title":"Summary","text":"Feature Status Persistent memory \u2714 Session-based retrieval \u2714 Project profile memory \u2714 Offline mode support \u2714 Noise cleaning \u2714 Vector search \u2718(planned) Metadata-based query filtering \u2718(planned)"},{"location":"server/","title":"Agent Server (FastAPI REST API)","text":"<p>The Multimodal Agent provides a lightweight HTTP server built on FastAPI, allowing external applications (Flutter, web, backend systems) to call the agent over HTTP.</p> <p>Start the server using:</p> <pre><code>agent server --port 8000\n</code></pre> <p>The API exposes endpoints for:</p> <ul> <li>Text generation (/generate)</li> <li>Image + text multimodal generation (/generate-image)</li> <li>JSON mode output</li> <li>Token usage reporting</li> </ul>"},{"location":"server/#start-the-server","title":"Start the Server","text":"<pre><code>agent server\n</code></pre> <p>Default port: 8000</p> <p>Override:</p> <pre><code>agent server --port 9000\n</code></pre>"},{"location":"server/#endpoints-overview","title":"Endpoints Overview","text":"Endpoint Method Description /generate POST Generate from text prompt /generate-image POST Generate from text + image /health GET Health check"},{"location":"server/#text-generation-api","title":"Text Generation API","text":""},{"location":"server/#post-generate","title":"POST /generate","text":"<p>Request:</p> <pre><code>{\n  \"prompt\": \"Write a short poem about stars\",\n  \"response_format\": \"text\",\n  \"session\": \"optional-session-id\"\n}\n</code></pre>"},{"location":"server/#response","title":"Response:","text":"<pre><code>{\n  \"text\": \"The stars drift softly...\",\n  \"data\": null,\n  \"usage\": {\n    \"prompt_tokens\": 17,\n    \"response_tokens\": 22,\n    \"total_tokens\": 39\n  }\n}\n</code></pre>"},{"location":"server/#json-mode-api","title":"JSON Mode API","text":"<p>Request:</p> <pre><code>{\n  \"prompt\": \"Return JSON with { name, age }\",\n  \"response_format\": \"json\"\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"text\": \"{\\\"name\\\": \\\"Alice\\\", \\\"age\\\": 25}\",\n  \"data\": {\n    \"name\": \"Alice\",\n    \"age\": 25\n  },\n  \"usage\": {\n    \"prompt_tokens\": 13,\n    \"response_tokens\": 12,\n    \"total_tokens\": 25\n  }\n}\n</code></pre>"},{"location":"server/#image-text-generation","title":"Image + Text Generation","text":""},{"location":"server/#post-generate-image","title":"POST /generate-image","text":"<p>Supports multimodal input using a base64-encoded image.</p> <p>Request:</p> <pre><code>{\n  \"prompt\": \"Describe this image\",\n  \"image_base64\": \"&lt;base64 string&gt;\",\n  \"mime_type\": \"image/jpeg\"\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"text\": \"A cat is sitting on a windowsill...\",\n  \"data\": null,\n  \"usage\": {\n    \"prompt_tokens\": 7,\n    \"response_tokens\": 18,\n    \"total_tokens\": 25\n  }\n}\n</code></pre>"},{"location":"server/#offline-mode-behavior","title":"Offline Mode Behavior","text":"<p>If GOOGLE_API_KEY is missing:</p>"},{"location":"server/#response-text-mode","title":"Response (text mode)","text":"<pre><code>{\n  \"text\": \"FAKE_RESPONSE: &lt;your prompt&gt;\",\n  \"data\": null,\n  \"usage\": {\n    \"prompt_tokens\": 10,\n    \"response_tokens\": 5,\n    \"total_tokens\": 15\n  }\n}\n</code></pre> <p>Useful for:</p> <ul> <li>CI testing</li> <li>Local development</li> <li>Deterministic behavior</li> </ul>"},{"location":"server/#quota-rate-limit-behavior-free-tier","title":"Quota &amp; Rate Limit Behavior (Free Tier)","text":"<p>When using the Gemini API free tier, the server may return:</p> <ul> <li>HTTP 429 \u2013 RESOURCE_EXHAUSTED</li> <li>Quota exceeded</li> <li>Request timeout</li> </ul> <p>This is expected behavior and not a server bug.</p> <p>Typical causes: - Daily request quota exhausted - Requests-per-minute (RPM) exceeded - Token limits reached</p> <p>Behavior: - Server returns HTTP 429 - VS Code extension shows an error notification - CLI may still work temporarily due to different execution paths</p> <p>Solutions: - Wait for quota reset (usually within 24 hours) - Reduce request frequency - Switch to a lighter model - Upgrade your Gemini API plan</p> <p>While quota is exhausted, offline fake mode continues to work.</p>"},{"location":"server/#model-configuration-errors","title":"Model Configuration Errors","text":"<p>If the configured model does not exist or is deprecated, the server may return:</p> <ul> <li>HTTP 400</li> <li>404 NOT_FOUND (model)</li> </ul> <p>Example: <pre><code>models/gemini-1.5-pro is not supported\n</code></pre></p> <p>Fix: -   Update chat_model or image_model in ~/.multimodal_agent/config.yaml -   Restart the agent server -   Verify available models at: https://ai.google.dev/gemini-api/docs/models</p>"},{"location":"server/#error-handling","title":"Error Handling","text":"<p>All errors follow a consistent schema:</p> <pre><code>{\n  \"error\": \"Invalid request\",\n  \"detail\": \"Field 'prompt' is required\",\n  \"status\": 400\n}\n</code></pre> <p>Internal agent errors:</p> <pre><code>{\n  \"error\": \"ModelError\",\n  \"detail\": \"Model failed to generate a response\",\n  \"status\": 500\n}\n</code></pre> <p>Note: The CLI may continue working while the server fails due to stricter HTTP timeouts and quota enforcement.</p>"},{"location":"server/#example-curl-commands","title":"Example: cURL Commands","text":"<p>Text:</p> <pre><code>curl -X POST http://localhost:8000/generate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"prompt\": \"hello\"}'\n</code></pre> <p>Image:</p> <pre><code>curl -X POST http://localhost:8000/generate-image \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"prompt\":\"What is in this image?\", \"image_base64\":\"&lt;...&gt;\"}'\n</code></pre>"},{"location":"server/#python-client-example","title":"Python Client Example","text":"<pre><code>import requests\n\nresp = requests.post(\n    \"http://localhost:8000/generate\",\n    json={\"prompt\": \"Hello world\"}\n)\n\nprint(resp.json())\n</code></pre>"},{"location":"server/#flutter-client-example","title":"Flutter Client Example","text":"<pre><code>final response = await http.post(\n  Uri.parse(\"http://localhost:8000/generate\"),\n  headers: {\"Content-Type\": \"application/json\"},\n  body: jsonEncode({\"prompt\": \"hello\"}),\n);\n\nfinal data = jsonDecode(response.body);\nprint(data[\"text\"]);\n</code></pre>"},{"location":"server/#future-server-extensions-v09x","title":"Future Server Extensions (v0.9.x)","text":"<p>The roadmap includes:</p> <ul> <li>SSE streaming endpoint (/stream)</li> <li>Code generation endpoint (/codegen)</li> <li>Endpoint for executing a chain of model calls</li> <li>Endpoint for RAG retrieval preview (/rag/inspect)</li> <li>Built-in authentication tokens</li> </ul>"},{"location":"server/#summary","title":"Summary","text":"<p>The server:</p> <p>\u2714 Provides clean, predictable JSON responses</p> <p>\u2714 Supports text, images, and JSON mode</p> <p>\u2714 Mirrors the exact behavior of the Python API</p> <p>\u2714 Works offline for tests and CI</p> <p>\u2714 Integrates cleanly with Flutter, Node, and backend services</p>"},{"location":"sessions/","title":"Sessions","text":"<p>Sessions allow the Multimodal-Agent to maintain context across multiple interactions.</p> <p>Each session has its own memory stream, enabling:</p> <ul> <li>Multi-turn conversations</li> <li>Independent threads of reasoning</li> <li>Separate RAG histories</li> <li>Clean isolation between tasks or projects</li> </ul>"},{"location":"sessions/#how-sessions-work","title":"How Sessions Work","text":"<p>Every interaction with the agent can be associated with a session ID:</p> <pre><code>agent ask \"Explain caching layers\" --session study\n</code></pre> <p>The same session ID can be used repeatedly:</p> <pre><code>agent ask \"Continue\" --session study\n</code></pre> <p>This lets the agent retrieve context from the RAG memory associated with that session.</p>"},{"location":"sessions/#why-sessions-matter","title":"Why Sessions Matter","text":"Feature Description Persistent conversation The agent remembers user messages and responses. Contextual RAG Retrieval is limited to entries from the same session (unless forced). Multi-session workflows You can maintain several \u201cworkspaces\u201d of knowledge. Better isolation Different projects or topics never interfere with each other."},{"location":"sessions/#session-ids-in-cli-commands","title":"Session IDs in CLI Commands","text":""},{"location":"sessions/#ask-command","title":"Ask command","text":"<pre><code>agent ask \"Hello\" --session chat1\n</code></pre>"},{"location":"sessions/#image-command","title":"Image command","text":"<pre><code>agent image pic.png \"Describe this\" --session design_experiment\n</code></pre>"},{"location":"sessions/#chat-mode-interactive","title":"Chat mode (interactive)","text":"<pre><code>agent chat --session daily\n</code></pre> <p>The session continues until you exit chat mode.</p>"},{"location":"sessions/#how-sessions-interact-with-rag-memory","title":"How Sessions Interact with RAG Memory","text":"<p>Each message added to the RAG store is tagged with:</p> <ul> <li>session_id</li> <li>role (user, assistant, or project_profile)</li> <li>timestamp</li> <li>source (ask, chat, project-learning, etc.)</li> </ul> <p>Example RAG record:</p> <pre><code>{\n  \"session_id\": \"study\",\n  \"content\": \"Explain transformers...\",\n  \"role\": \"user\",\n  \"source\": \"ask\"\n}\n</code></pre> <p>When the agent receives a query:</p> <ol> <li>It looks for relevant RAG entries only within the same session</li> <li>Applies vector similarity</li> <li>Constructs a retrieval-augmented prompt</li> <li>Produces a contextual answer</li> </ol> <p>Disable RAG for stateless interactions:</p> <pre><code>agent ask \"hello\" --no-rag\n</code></pre>"},{"location":"sessions/#offline-mode-no-api-key","title":"Offline Mode (No API Key)","text":"<p>If no GOOGLE_API_KEY is found:</p> <ul> <li>Sessions still work</li> <li>RAG still stores and retrieves memory</li> <li>The model returns deterministic FAKE_RESPONSE: answers</li> <li>No external API calls are made</li> </ul> <p>This is ideal for:</p> <ul> <li>testing</li> <li>CI pipelines</li> <li>working offline</li> </ul> <p>Example:</p> <pre><code>agent ask \"hello\" --session test\n</code></pre> <p>Produces:</p> <pre><code>FAKE_RESPONSE: hello\n</code></pre>"},{"location":"sessions/#managing-session-memory","title":"Managing Session Memory","text":""},{"location":"sessions/#view-recent-history","title":"View recent history","text":"<pre><code>agent history show --session study\n</code></pre>"},{"location":"sessions/#view-only-last-n-items","title":"View only last N items","text":"<pre><code>agent history show --limit 20 --session study\n</code></pre>"},{"location":"sessions/#show-cleaned-history-no-fake_response-no-system-noise","title":"Show cleaned history (no FAKE_RESPONSE, no system noise)","text":"<pre><code>agent history show --clean --session study\n</code></pre>"},{"location":"sessions/#clear-all-memory","title":"Clear all memory","text":"<pre><code>agent history clear\n</code></pre>"},{"location":"sessions/#delete-a-specific-entry","title":"Delete a specific entry","text":"<pre><code>agent history delete 42\n</code></pre>"},{"location":"sessions/#recommended-session-naming-conventions","title":"Recommended Session Naming Conventions","text":"<p>Use short, descriptive names:</p> <ul> <li>flutter_app</li> <li>thesis</li> <li>design_review</li> <li>bugfix_123</li> <li>morning_chat</li> </ul> <p>Avoid:</p> <ul> <li>very long names</li> <li>names with spaces</li> <li>names used for unrelated topics</li> </ul>"},{"location":"sessions/#quick-examples","title":"Quick Examples","text":""},{"location":"sessions/#math-session","title":"Math session","text":"<pre><code>agent ask \"What is Fourier transform?\" --session math\nagent ask \"Give me an example\" --session math\n</code></pre>"},{"location":"sessions/#flutter-session","title":"Flutter session","text":"<pre><code>agent ask \"How do I use Navigator 2.0?\" --session flutter\n</code></pre>"},{"location":"sessions/#debug-session","title":"Debug session","text":"<pre><code>agent chat --session debug_issue\n</code></pre>"},{"location":"sessions/#summary","title":"Summary","text":"Feature Status Persistent chat history \u2714\ufe0f Session-scoped RAG retrieval \u2714\ufe0f Isolated memory streams \u2714\ufe0f Works offline \u2714\ufe0f FAKE_RESPONSE mode Fully supported across ask/image/chat \u2714\ufe0f CLI + API support \u2714\ufe0f"},{"location":"token_usage/","title":"Token Usage Logging","text":"<p>The Multimodal Agent automatically tracks token usage for:</p> <ul> <li>Text-only generation</li> <li>Image + text multimodal generation</li> <li>JSON mode</li> <li>Offline FAKE mode</li> </ul> <p>Every response\u2014CLI, Python API, or Server\u2014includes a standardized usage dictionary.</p>"},{"location":"token_usage/#what-is-logged","title":"What Is Logged?","text":"<p>Every model call (real or offline) returns:</p> <pre><code>{\n  \"prompt_tokens\": &lt;int&gt;,\n  \"response_tokens\": &lt;int&gt;,\n  \"total_tokens\": &lt;int&gt;\n}\n</code></pre> <p>These values appear under:</p> <pre><code>response.usage\n</code></pre> <p>Example (Python):</p> <pre><code>resp = agent.ask(\"Hello\")\nprint(resp.usage)\n</code></pre> <p>Output:</p> <pre><code>{ \"prompt_tokens\": 5, \"response_tokens\": 12, \"total_tokens\": 17 }\n</code></pre>"},{"location":"token_usage/#logging-in-online-mode","title":"Logging in Online Mode","text":"<p>When a real model is used, the agent extracts token usage from the Gemini API response.</p> <p>Example server output:</p> <pre><code>{\n  \"text\": \"Hello!\",\n  \"usage\": {\n    \"prompt_tokens\": 7,\n    \"response_tokens\": 4,\n    \"total_tokens\": 11\n  }\n}\n</code></pre>"},{"location":"token_usage/#logging-in-offline-fake-mode","title":"Logging in Offline Fake Mode","text":"<p>If no API key is set:</p> <pre><code>export GOOGLE_API_KEY=\"\"\n</code></pre> <p>Then responses are generated deterministically, and token usage is simulated:</p> <p>Example:</p> <pre><code>{\n  \"text\": \"FAKE_RESPONSE: test\",\n  \"usage\": {\n    \"prompt_tokens\": 4,\n    \"response_tokens\": 5,\n    \"total_tokens\": 9\n  }\n}\n</code></pre> <p>This ensures:</p> <p>\u2714 CI tests remain stable</p> <p>\u2714 No API cost</p> <p>\u2714 CLI, server, and Python API behave identically</p>"},{"location":"token_usage/#cli-usage-logging","title":"CLI Usage Logging","text":"<p>Use:</p> <pre><code>agent ask \"hello\" --debug\n</code></pre> <p>Output includes:</p> <pre><code>[usage] prompt=5 response=12 total=17\n</code></pre>"},{"location":"token_usage/#server-usage-logging","title":"Server Usage Logging","text":"<p>All server responses include token usage:</p> <pre><code>{\n  \"text\": \"...\",\n  \"usage\": {\n    \"prompt_tokens\": 11,\n    \"response_tokens\": 18,\n    \"total_tokens\": 29\n  }\n}\n</code></pre> <p>This allows frontends (Flutter, React, etc.) to track cost in real time.</p>"},{"location":"token_usage/#python-api-usage-logging","title":"Python API Usage Logging","text":"<pre><code>resp = agent.ask(\"Explain gravity\")\nprint(resp.usage[\"total_tokens\"])\n</code></pre> <p>Works exactly the same for:</p> <ul> <li>agent.ask_with_image()</li> <li>JSON mode</li> <li>Offline mode</li> </ul>"},{"location":"token_usage/#where-usage-is-stored","title":"Where Usage Is Stored","text":"<p>Token usage is not persisted in the RAG memory database.</p> <p>It is only returned per-response.</p>"},{"location":"token_usage/#future-extensions-v09x","title":"Future Extensions (v0.9.x)","text":"<p>Planned improvements:</p> <ul> <li>Usage logging per-session</li> <li>Cost estimation (USD)</li> <li>Project-level usage breakdown</li> <li>Heatmap of RAG vs direct model calls</li> </ul>"},{"location":"token_usage/#summary","title":"Summary","text":"<p>Token usage logging is:</p> <p>\u2714 Always included</p> <p>\u2714 Consistent across all modes</p> <p>\u2714 Deterministic in offline mode</p> <p>\u2714 Available in CLI, Server, and Python API</p> <p>If you want, I can update chunk_normalization.md next, or skip planned features and continue with config.md, sessions.md, or anything you choose.</p> <p>Just say \u201cnext\u201d.</p>"},{"location":"usage_logging/","title":"Usage Logging","text":"<p>The Multimodal-Agent includes optional token usage tracking, which helps you understand:</p> <ul> <li>How many tokens your prompts consumed</li> <li>How many tokens the model responded with</li> <li>The total cost of an interaction</li> <li>Whether the model ran online or offline</li> </ul> <p>Usage logging is off by default to keep the console clean unless you explicitly request it.</p>"},{"location":"usage_logging/#how-usage-logging-works","title":"How Usage Logging Works","text":"<p>Every response includes an internal usage dictionary:</p> <pre><code>{\n    \"prompt_tokens\": 123,\n    \"response_tokens\": 45,\n    \"total_tokens\": 168\n}\n</code></pre> <p>When running through the CLI:</p> <pre><code>agent ask \"Hello\" --debug\n</code></pre> <p>The agent prints:</p> <pre><code>[usage] prompt=123 response=45 total=168\n</code></pre> <p>Debug mode automatically shows usage logging.</p>"},{"location":"usage_logging/#offline-mode-fake-usage","title":"Offline Mode (Fake Usage)","text":"<p>When no API key is provided:</p> <pre><code>export GOOGLE_API_KEY=\"\"\nagent ask \"hello\"\n</code></pre> <p>The agent switches to a fake offline mode, returning:</p> <ul> <li>FAKE_RESPONSE: ...</li> <li>synthetic token usage values</li> </ul> <p>This is essential for:</p> <ul> <li>running tests</li> <li>CI environments</li> <li>developing without spending tokens</li> </ul> <p>Example:</p> <pre><code>AgentResponse(\n    text=\"FAKE_RESPONSE: hello\",\n    usage={\n        \"prompt_tokens\": 5,\n        \"response_tokens\": 5,\n        \"total_tokens\": 10\n    }\n)\n</code></pre> <p>This allows unit tests to assert offline behavior consistently.</p>"},{"location":"usage_logging/#usage-logging-in-tests","title":"Usage Logging in Tests","text":"<p>The test suite includes multiple checks:</p>"},{"location":"usage_logging/#1-validate-usage-values-exist","title":"1. Validate usage values exist","text":"<pre><code>assert result.usage[\"total_tokens\"] &gt; 0\n</code></pre>"},{"location":"usage_logging/#2-test-offline-mode-produces-fake_response","title":"2. Test offline mode produces FAKE_RESPONSE","text":"<pre><code>monkeypatch.setenv(\"GOOGLE_API_KEY\", \"\")\nresult = agent.ask(\"hello\")\nassert \"FAKE_RESPONSE\" in result.text\n</code></pre>"},{"location":"usage_logging/#3-json-mode-excludes-data-in-offline-mode","title":"3. JSON mode excludes data in offline mode","text":"<pre><code>assert result.data is None\n</code></pre>"},{"location":"usage_logging/#enabling-usage-logging-programmatically","title":"Enabling Usage Logging Programmatically","text":"<p>Usage logging lives at:</p> <pre><code>agent.usage_logging = True\n</code></pre> <p>Example:</p> <pre><code>from multimodal_agent import MultiModalAgent\n\nagent = MultiModalAgent()\nagent.usage_logging = True\n\nresponse = agent.ask(\"hello\")\nprint(response.usage)\n</code></pre>"},{"location":"usage_logging/#when-usage-logging-is-automatically-suppressed","title":"When Usage Logging Is Automatically Suppressed","text":"<p>Some operations suppress usage logs:</p> <ul> <li>During code generation (agent gen widget ...)</li> <li>Inside project learning</li> <li>While writing to RAG</li> <li>When output is meant to be clean (e.g., pure Dart output)</li> </ul>"},{"location":"usage_logging/#summary","title":"Summary","text":"Feature Status Token counting \u2714\ufe0f Fully supported Fake usage offline mode \u2714\ufe0f Used when API key missing Automatic logging \u2714\ufe0f via--debug Programmatic logging \u2714\ufe0f viaagent.usage_logging = True JSON mode compatibility \u2714\ufe0f Ensures clean metadata Used in tests \u2714\ufe0f Required for consistency"},{"location":"api/multimodal_agent/","title":"multimodal_agent","text":"<p>This module provides the main high-level interface for interacting with Gemini models using text, images, and optional RAG storage.</p>"},{"location":"api/multimodal_agent/#constructor","title":"Constructor","text":"<pre><code>MultiModalAgent(\n    model=\"gemini-2.0-flash-lite\",\n    enable_rag=False,\n    rag_store=None,\n    embedding_model=\"embedding-001\",\n)\n</code></pre>"},{"location":"api/multimodal_agent/#methods","title":"Methods","text":"<p><code>ask(question: str, response_format=\"text\") -&gt; AgentResponse</code></p> <p>Send a text prompt.</p> <pre><code>resp = agent.ask(\"hello\")\nresp.text   # string\nresp.usage  # token usage dict\n</code></pre> <p>JSON example:</p> <p><pre><code>resp = agent.ask(\"give json\", response_format=\"json\")\nresp.data   # parsed dict\n</code></pre> <code>ask_with_image(question: str, image: Part, response_format=\"text\") -&gt; AgentResponse</code></p> <p>Send a question with an image part.</p> <p><code>chat(...)</code></p> <p>Multi-turn conversation interface.</p> <p><code>AgentResponse</code></p> <p>Returned by all calls:</p>"},{"location":"api/multimodal_agent/#resptext-raw-response-text-respdata-dict-for-json-mode-else-none-respusage-token-metadata","title":"<pre><code>resp.text   # raw response text\nresp.data   # dict for JSON mode, else None\nresp.usage  # token metadata\n</code></pre>","text":""},{"location":"api/multimodal_agent/#utilities","title":"Utilities","text":"<p><code>load_image_as_part(path)</code></p> <p>Loads an image from disk and converts it into a Gemini-compatible Part.</p>"},{"location":"api/multimodal_agent/#rag-components","title":"RAG Components","text":"<p>The agent supports plug-and-play RAG via:</p> <ul> <li> <p><code>rag_store.add_logical_message</code></p> </li> <li> <p><code>rag_store.add_embedding</code></p> </li> <li> <p><code>rag_store.search_similar</code></p> </li> </ul> <p>See <code>docs/rag_store.md</code> for details.</p>"}]}