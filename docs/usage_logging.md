# Token Usage Logging

Introduced in **v.0.3.2** Multimodal-Agent can automatically record token usage for monitoring, experimentation, and cost awareness.

## How It Works

After each LLM request (online or offline), the agent writes a single line to:

```bash
~/.multimodal_agent/usage.log
```

**Example:**

2025-01-12T10:11:31Z | model=gemini-2.5-flash | prompt=53 | response=12 | total=65

The log directory is created automatically if missing.

## Enable / Disable

Usage logging isn automatically record t

```python
agent.usage_logging = False
```

## Custom Log Location

```python
agent.usage_log_path = "/var/log/agent_tokens.log"
```

If the folder does not exist, the agent attempts to create it safely.

## What is Logged?

| **Field**   | **Meaning** |
|-------------|-------------|
| `timestamp` | UTC timestamp in ISO-8601 format (e.g., `2025-11-29T15:23:45Z`). |
| `model`     | The specific model used for the request (e.g., `gpt-5.1`). |
| `prompt`    | Number of input tokens consumed (your message + system instructions). |
| `response`  | Number of output tokens generated by the model. |
| `total`     | Total token count: `prompt + response`. |



## Works Everywhere
Token usage logging supports:

- ask()
- ask_with_image()
- JSON response mode
- offline FakeResponse mode
- retry logic paths
- chat mode

Logging is fully isolated from the main execution path and cannot raise exceptions.

## When To Disable

You may turn logging off if:

- running automated load tests
- storing results in your own telemetry system
- you need a zero-logging environment

Disable:

```python
agent.usage_logging = False
```
